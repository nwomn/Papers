# MultimodalGatedDeltaNet 详细架构示意图

> 配置: B=2, L=1024, D=512, H=4, d=64, E=3 (shared + text + vision), expand_v=2
>
> 代码行号标注格式: `← Lxxx` 表示对应 `multimodal_gated_deltanet/layer.py` 的第 xxx 行

---

## 完整架构总览图

```
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃                              MultimodalGatedDeltaNet Layer                               ┃
┃                        (三专家多模态门控 Delta 注意力机制)                                  ┃
┃                                                                                          ┃
┃  代码文件: multimodal_gated_deltanet/layer.py                                            ┃
┃  主类: MultimodalGatedDeltaNet                                                           ┃
┃                                                                                          ┃
┃  核心特性:                                                                               ┃
┃    • 三个固定专家分支: Shared (始终激活) + Text + Vision                                  ┃
┃    • 三个独立状态空间: S_shared, S_text, S_vision                                        ┃
┃    • 基于 modality_ids 的选择性状态更新                                                   ┃
┃    • Q共享设计: 同一Q查询所有状态 o = Σ w_e * (q * S_e)                                  ┃
┃    • K专家扩展: 不同模态使用不同的K投影进行状态索引                                       ┃
┗━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┛
                                           │
                                           ▼
┌─────────────────────────────────────────────────────────────────────────────────────────┐
│  INPUT                                                                      ← L375      │
│  hidden_states: [B=2, L=1024, D=512]                                                    │
│  modality_ids:  [B=2] 或 [B=2, L=1024]  (支持序列级和Token级)                           │
│                                                                                         │
│  batch_size, seq_len, _ = hidden_states.shape                                           │
└─────────────────────────────────────────────────────────────────────────────────────────┘
                                           │
          ┌────────────────────────────────┼────────────────────────────────┐
          │                                │                                │
          ▼                                ▼                                ▼
┌─────────────────────┐      ┌─────────────────────┐      ┌─────────────────────┐
│     Q Projection    │      │     K Projection    │      │     V Projection    │
│  ┌───────────────┐  │      │  ┌───────────────┐  │      │  ┌───────────────┐  │
│  │ Linear        │  │      │  │ Linear        │  │      │  │ Linear        │  │
│  │ W: [512, 256] │  │      │  │ W: [512, 256] │  │      │  │ W: [512, 512] │  │
│  │ Params: 131K  │  │      │  │ Params: 131K  │  │      │  │ Params: 262K  │  │
│  └───────────────┘  │      │  └───────────────┘  │      │  └───────────────┘  │
│  Out: [2,1024,256]  │      │  Out: [2,1024,256]  │      │  Out: [2,1024,512]  │
│        ← L401       │      │        ← L402       │      │        ← L403       │
└─────────────────────┘      └─────────────────────┘      └─────────────────────┘
          │                                │                                │
          ▼                                ▼                                ▼
┌─────────────────────────────────────────────────────────────────────────────────────────┐
│  RESHAPE TO MULTI-HEAD FORMAT                                               ← L406-408  │
│  ═══════════════════════════════════════════════════════════════════════════════════   │
│  q_base: [2,1024,256] → rearrange('b l (h d) -> h b l d') → [H=4, B=2, L=1024, d=64]   │
│  k_base: [2,1024,256] → rearrange('b l (h d) -> h b l d') → [4, 2, 1024, 64]           │
│  v_base: [2,1024,512] → rearrange('b l (h d) -> h b l d') → [4, 2, 1024, 128]          │
└─────────────────────────────────────────────────────────────────────────────────────────┘
                                           │
                    ┌──────────────────────┴──────────────────────┐
                    │                                            │
                    ▼                                            ▼
┌───────────────────────────────────────┐    ┌───────────────────────────────────────────┐
│      UPDATE MASK GENERATION           │    │      EXPERT-SPECIFIC K EXPANSION          │
│            ← L411                     │    │              ← L420-438                   │
│  ┌─────────────────────────────────┐  │    │                                           │
│  │ Input: modality_ids [B=2]       │  │    │  ┌─────────────────────────────────────┐  │
│  │                                 │  │    │  │ Q: SHARED (same question to all)    │  │
│  │ modality_ids = [0, 1]          │  │    │  │   q_all = repeat(q_base, E=3)       │  │
│  │  (text, vision)                │  │    │  │   Shape: [H,B,L,d] → [E,H,B,L,d]    │  │
│  │                                 │  │    │  │   (3 copies of same Q)              │  │
│  │ ┌─────────────────────────────┐│  │    │  │                                     │  │
│  │ │ Generate update_mask        ││  │    │  │ K: EXPANDED per-expert              │  │
│  │ │                             ││  │    │  │   expert_k_proj_expand[E][H]:       │  │
│  │ │ Expert 0 (Shared): [1, 1]   ││  │    │  │   Linear(64 → 64) × 3 × 4           │  │
│  │ │ Expert 1 (Text):   [1, 0]   ││  │    │  │   Params: 49K                       │  │
│  │ │ Expert 2 (Vision): [0, 1]   ││  │    │  │   (different encoding per modality) │  │
│  │ │                             ││  │    │  │                                     │  │
│  │ │ update_mask: [E=3,B=2,L,H]  ││  │    │  │ V: SHARED (same content)            │  │
│  │ └─────────────────────────────┘│  │    │  │   v_all = repeat(v_base, E=3)       │  │
│  └─────────────────────────────────┘  │    │  └─────────────────────────────────────┘  │
│                                       │    │                                           │
│  ┌─────────────────────────────────┐  │    │  Output shapes:                           │
│  │    Update Mask Visualization    │  │    │    q_all: [E=3, H=4, B=2, L=1024, d=64]  │
│  │                                 │  │    │           (3 copies identical)           │
│  │  Expert │ Batch 0 │ Batch 1    │  │    │    k_all: [E=3, H=4, B=2, L=1024, d=64]  │
│  │  ───────┼─────────┼──────────  │  │    │           (3 different projections)      │
│  │  Shared │   ████  │   ████     │  │    │    v_all: [E=3, H=4, B=2, L=1024, d=128] │
│  │  Text   │   ████  │            │  │    │           (3 copies identical)           │
│  │  Vision │         │   ████     │  │    └───────────────────────────────────────────┘
│  │                                 │  │
│  └─────────────────────────────────┘  │
└───────────────────────────────────────┘
                    │                                            │
                    │         ┌──────────────────────────────────┘
                    │         │
                    │         ▼
                    │    ┌───────────────────────────────────────────────────────────────┐
                    │    │  MERGE FOR CONVOLUTION                             ← L441-443  │
                    │    │  ═══════════════════════════════════════════════════════════ │
                    │    │  q_flat: [3,4,2,1024,64] → '(e b) l (h d)' → [6, 1024, 256]  │
                    │    │  k_flat: [3,4,2,1024,64] → '(e b) l (h d)' → [6, 1024, 256]  │
                    │    │  v_flat: [3,4,2,1024,128] → '(e b) l (h d)' → [6, 1024, 512] │
                    │    └───────────────────────────────────────────────────────────────┘
                    │                                            │
                    │                                            ▼
                    │    ┌───────────────────────────────────────────────────────────────┐
                    │    │  SHORT CONVOLUTION (Shared across experts)        ← L455-466  │
                    │    │  ┌─────────────────┬─────────────────┬─────────────────┐     │
                    │    │  │   q_conv1d      │   k_conv1d      │   v_conv1d      │     │
                    │    │  │ kernel_size=4   │ kernel_size=4   │ kernel_size=4   │     │
                    │    │  │ hidden=256      │ hidden=256      │ hidden=512      │     │
                    │    │  │ + SiLU activ.   │ + SiLU activ.   │ + SiLU activ.   │     │
                    │    │  └─────────────────┴─────────────────┴─────────────────┘     │
                    │    │  q_flat: [6,1024,256] → [6,1024,256]                         │
                    │    │  k_flat: [6,1024,256] → [6,1024,256]                         │
                    │    │  v_flat: [6,1024,512] → [6,1024,512]                         │
                    │    └───────────────────────────────────────────────────────────────┘
                    │                                            │
                    │                                            ▼
                    │    ┌───────────────────────────────────────────────────────────────┐
                    │    │  RESHAPE BACK TO EXPERT DIMENSIONS                 ← L469-471 │
                    │    │  ═══════════════════════════════════════════════════════════ │
                    │    │  q_all: [6,1024,256] → '(e b) l (h d) -> e b l h d'          │
                    │    │                     → [E=3, B=2, L=1024, H=4, d=64]          │
                    │    │  k_all: same → [3, 2, 1024, 4, 64]                           │
                    │    │  v_all: same → [3, 2, 1024, 4, 128]                          │
                    │    └───────────────────────────────────────────────────────────────┘
                    │                                            │
                    └────────────────────────────────────────────┤
                                                                 │
                                                                 ▼
┌─────────────────────────────────────────────────────────────────────────────────────────┐
│  APPLY UPDATE MASK (Key Difference from MoE!)                           ← L476-478     │
│  ═══════════════════════════════════════════════════════════════════════════════════   │
│                                                                                         │
│  ┌─────────────────────────────────────────────────────────────────────────────────┐  │
│  │ CRITICAL: Q is NOT masked! Only K, V are masked                                 │  │
│  │                                                                                  │  │
│  │ • Q queries ALL three states (shared + text + vision)                           │  │
│  │ • K, V masked → controls which states get UPDATED                               │  │
│  │                                                                                  │  │
│  │   k_all = k_all * update_mask[..., None]    # K masked                          │  │
│  │   v_all = v_all * update_mask[..., None]    # V masked                          │  │
│  │   # q_all is NOT masked!                    # Q not masked                       │  │
│  │                                                                                  │  │
│  │ Effect:                                                                          │  │
│  │ ┌─────────────────────────────────────────────────────────────────────────────┐ │  │
│  │ │ Batch 0 (text sequence):                                                     │ │  │
│  │ │   S_shared: UPDATED (k,v ≠ 0)                                               │ │  │
│  │ │   S_text:   UPDATED (k,v ≠ 0)                                               │ │  │
│  │ │   S_vision: NOT UPDATED (k,v = 0) but still QUERIED!                        │ │  │
│  │ │                                                                              │ │  │
│  │ │ Batch 1 (vision sequence):                                                   │ │  │
│  │ │   S_shared: UPDATED                                                         │ │  │
│  │ │   S_text:   NOT UPDATED but still QUERIED!                                  │ │  │
│  │ │   S_vision: UPDATED                                                         │ │  │
│  │ └─────────────────────────────────────────────────────────────────────────────┘ │  │
│  └─────────────────────────────────────────────────────────────────────────────────┘  │
│                                                                                         │
└─────────────────────────────────────────────────────────────────────────────────────────┘
                                                                 │
                                                                 ▼
┌─────────────────────────────────────────────────────────────────────────────────────────┐
│  GATING PARAMETERS (β and γ) with Update Mask                       ← L481-495         │
│  ═══════════════════════════════════════════════════════════════════════════════════   │
│                                                                                         │
│  ┌──────────────────────────────────┐  ┌──────────────────────────────────────────┐    │
│  │ Beta (Input Gate)     ← L481     │  │ Gamma (Decay Gate)          ← L485       │    │
│  │ ────────────────────             │  │ ────────────────────                     │    │
│  │ b_proj: Linear(512 → 12)         │  │ a_proj: Linear(512 → 12)                 │    │
│  │         (E×H = 3×4 = 12)         │  │ A_log: Parameter([12])                   │    │
│  │ Params: 6.1K                     │  │ dt_bias: Parameter([12])                 │    │
│  │                                  │  │                                          │    │
│  │ beta = sigmoid(b_proj(x))        │  │ g = -exp(A_log) * softplus(a_proj(x) +   │    │
│  │ [2,1024,512] → [2,1024,12]       │  │                           dt_bias)       │    │
│  │       ↓ rearrange                │  │ [2,1024,12] → [3,2,1024,4]               │    │
│  │ [E=3, B=2, L=1024, H=4]          │  │       ↓ × update_mask                    │    │
│  │       ↓ × update_mask            │  │ [3, 2, 1024, 4] (masked)                 │    │
│  │ [3, 2, 1024, 4] (masked)         │  │                                          │    │
│  └──────────────────────────────────┘  └──────────────────────────────────────────┘    │
│                                                                                         │
│  When update_mask = 0:  beta = 0, g = 0  →  State NOT updated                          │
│  When update_mask = 1:  beta > 0, g < 0  →  State IS updated                           │
│                                                                                         │
└─────────────────────────────────────────────────────────────────────────────────────────┘
                                                                 │
                                                                 ▼
┌─────────────────────────────────────────────────────────────────────────────────────────┐
│  MERGE FOR GATED DELTA RULE                                         ← L507-511         │
│  ═══════════════════════════════════════════════════════════════════════════════════   │
│                                                                                         │
│  Step 1: Merge experts and heads into single head dimension                            │
│  ────────────────────────────────────────────────────────────────────────────────      │
│  q: [3,2,1024,4,64]  → 'e b l h d -> b l (e h) d' → [2, 1024, 12, 64]                  │
│  k: [3,2,1024,4,64]  →                            → [2, 1024, 12, 64]                  │
│  v: [3,2,1024,4,128] →                            → [2, 1024, 12, 128]                 │
│  g: [3,2,1024,4]     →                            → [2, 1024, 12]                      │
│  beta: [3,2,1024,4]  →                            → [2, 1024, 12]                      │
│                                                                                         │
│  Note: 12 = E×H = 3 experts × 4 heads                                                  │
│                                                                                         │
└─────────────────────────────────────────────────────────────────────────────────────────┘
                                                                 │
                                                                 ▼
┌─────────────────────────────────────────────────────────────────────────────────────────┐
│  GATED DELTA RULE COMPUTATION (Core Recurrence)                     ← L527-550         │
│  ═══════════════════════════════════════════════════════════════════════════════════   │
│                                                                                         │
│  chunk_gated_delta_rule(                                                               │
│      q     = [2, 1024, 12, 64],    # [B, L, H', d_k]                                   │
│      k     = [2, 1024, 12, 64],    # [B, L, H', d_k]                                   │
│      v     = [2, 1024, 12, 128],   # [B, L, H', d_v]                                   │
│      g     = [2, 1024, 12],        # [B, L, H']                                        │
│      beta  = [2, 1024, 12],        # [B, L, H']                                        │
│  )                                                                                      │
│                                                                                         │
│  ┌─────────────────────────────────────────────────────────────────────────────────┐  │
│  │                         State Update Equation                                   │  │
│  │  ═══════════════════════════════════════════════════════════════════════════   │  │
│  │                                                                                  │  │
│  │  For each "virtual head" h ∈ [0, 11] (3 experts × 4 heads):                     │  │
│  │                                                                                  │  │
│  │  ┌─────────────────────────────────────────────────────────────────────────┐   │  │
│  │  │   S_t = g_t · S_{t-1} + β_t · (k_t^T ⊗ v_t)                            │   │  │
│  │  │                                                                          │   │  │
│  │  │   where:                                                                 │   │  │
│  │  │     S_t    : [d_k, d_v] = [64, 128]  (state matrix per head)            │   │  │
│  │  │     g_t    : scalar (decay gate, ∈ [-16, 0] when active, 0 when masked) │   │  │
│  │  │     β_t    : scalar (input gate, ∈ [0, 1] when active, 0 when masked)   │   │  │
│  │  │     k_t    : [d_k] = [64]   (0 when masked → no update)                 │   │  │
│  │  │     v_t    : [d_v] = [128]  (0 when masked → no update)                 │   │  │
│  │  └─────────────────────────────────────────────────────────────────────────┘   │  │
│  │                                                                                  │  │
│  │  ┌─────────────────────────────────────────────────────────────────────────┐   │  │
│  │  │   o_t = q_t · S_t                                                       │   │  │
│  │  │                                                                          │   │  │
│  │  │   Note: q_t is NOT masked, so ALL states are queried!                   │   │  │
│  │  │     Even S_vision is queried when processing text sequence              │   │  │
│  │  │                                                                          │   │  │
│  │  │     q_t : [d_k] = [64]  (always non-zero)                               │   │  │
│  │  │     S_t : [d_k, d_v] = [64, 128]                                        │   │  │
│  │  │     o_t : [d_v] = [128]                                                 │   │  │
│  │  └─────────────────────────────────────────────────────────────────────────┘   │  │
│  │                                                                                  │  │
│  │  Recurrent State Memory:                                                        │  │
│  │    S: [B=2, H'=12, d_k=64, d_v=128] = 1.57 MB (fixed, independent of L!)       │  │
│  │                                                                                  │  │
│  └─────────────────────────────────────────────────────────────────────────────────┘  │
│                                                                                         │
│  Output: o = [2, 1024, 12, 128]                                                        │
│                                                                                         │
└─────────────────────────────────────────────────────────────────────────────────────────┘
                                                                 │
                                                                 ▼
┌─────────────────────────────────────────────────────────────────────────────────────────┐
│  RESHAPE BACK TO EXPERT DIMENSIONS                                  ← L558             │
│  ═══════════════════════════════════════════════════════════════════════════════════   │
│                                                                                         │
│  o: [2,1024,12,128] → rearrange('b l (e h) d -> e b l h d', e=3, h=4)                  │
│                     → [E=3, B=2, L=1024, H=4, d=128]                                   │
│                                                                                         │
└─────────────────────────────────────────────────────────────────────────────────────────┘
                                                                 │
                                                                 ▼
┌─────────────────────────────────────────────────────────────────────────────────────────┐
│  OUTPUT AGGREGATION WITH LEARNABLE WEIGHTS (Key Innovation!)        ← L566-567         │
│  ═══════════════════════════════════════════════════════════════════════════════════   │
│                                                                                         │
│  ┌─────────────────────────────────────────────────────────────────────────────────┐  │
│  │ Learnable Output Weights                                             ← L194     │  │
│  │ ────────────────────────                                                        │  │
│  │ self.output_weights = nn.Parameter(torch.zeros(E=3, H=4))                       │  │
│  │                                                                                  │  │
│  │ Forward:                                                                         │  │
│  │   weights = F.softmax(self.output_weights, dim=0)  # [3, 4] → normalized        │  │
│  │                                                                                  │  │
│  │ Initial (all zeros):                                                            │  │
│  │   softmax([0,0,0]) = [0.333, 0.333, 0.333]  # Equal weight                      │  │
│  │                                                                                  │  │
│  │ After training (example):                                                        │  │
│  │   Expert   │ Head 0 │ Head 1 │ Head 2 │ Head 3                                  │  │
│  │   ─────────┼────────┼────────┼────────┼────────                                 │  │
│  │   Shared   │  0.40  │  0.35  │  0.45  │  0.38                                   │  │
│  │   Text     │  0.35  │  0.40  │  0.30  │  0.32                                   │  │
│  │   Vision   │  0.25  │  0.25  │  0.25  │  0.30                                   │  │
│  │             (sum=1)  (sum=1)  (sum=1)  (sum=1)                                   │  │
│  └─────────────────────────────────────────────────────────────────────────────────┘  │
│                                                                                         │
│  ┌─────────────────────────────────────────────────────────────────────────────────┐  │
│  │ Weighted Aggregation                                                             │  │
│  │ ────────────────────                                                            │  │
│  │                                                                                  │  │
│  │   o_final = Σ_{e=0}^{2} (weight[e] × o[e])                                      │  │
│  │                                                                                  │  │
│  │   o: [E=3, B=2, L=1024, H=4, d=128]                                             │  │
│  │   weights: [E=3, H=4]                                                           │  │
│  │                                                                                  │  │
│  │   einsum('eblhd, eh -> blhd')                                                   │  │
│  │                                                                                  │  │
│  │   o_final = w_shared × o_shared + w_text × o_text + w_vision × o_vision         │  │
│  │                                                                                  │  │
│  │   ┌───────────────────────────────────────────────────────────────────────┐     │  │
│  │   │ ALL THREE STATES CONTRIBUTE TO OUTPUT!                                 │     │  │
│  │   │                                                                        │     │  │
│  │   │ For text sequence (batch 0):                                           │     │  │
│  │   │   o = w_sh × (q·S_shared) + w_txt × (q·S_text) + w_vis × (q·S_vision)│     │  │
│  │   │                    ↑                  ↑                    ↑           │     │  │
│  │   │               updated            updated           NOT updated         │     │  │
│  │   │               (fresh)            (fresh)           (historical)        │     │  │
│  │   │                                                                        │     │  │
│  │   │ This allows cross-modal information sharing!                           │     │  │
│  │   └───────────────────────────────────────────────────────────────────────┘     │  │
│  │                                                                                  │  │
│  └─────────────────────────────────────────────────────────────────────────────────┘  │
│                                                                                         │
│  Output: o = [B=2, L=1024, H=4, d=128]                                                 │
│                                                                                         │
└─────────────────────────────────────────────────────────────────────────────────────────┘
                                                                 │
                                                                 ▼
┌─────────────────────────────────────────────────────────────────────────────────────────┐
│  OUTPUT GATING & PROJECTION                                         ← L583-590         │
│  ═══════════════════════════════════════════════════════════════════════════════════   │
│                                                                                         │
│  ┌─────────────────────────────────────────────────────────────────────────────────┐  │
│  │ Gate Projection                                                    ← L583       │  │
│  │ ────────────────                                                                │  │
│  │ g_proj: Linear(512 → 512), Params: 262K                                         │  │
│  │                                                                                  │  │
│  │ g = g_proj(hidden_states)                                                       │  │
│  │ [2,1024,512] → [2,1024,512]                                                     │  │
│  │        ↓ rearrange('b l (h d) -> b l h d', h=4)                                 │  │
│  │ [2,1024,4,128]                                                                  │  │
│  └─────────────────────────────────────────────────────────────────────────────────┘  │
│                                                                                         │
│  ┌─────────────────────────────────────────────────────────────────────────────────┐  │
│  │ Fused RMSNorm + Swish Gate                                         ← L584       │  │
│  │ ─────────────────────────────                                                   │  │
│  │ o_norm: FusedRMSNormSwishGate(head_v_dim=128, eps=1e-5)                         │  │
│  │                                                                                  │  │
│  │ o = o_norm(o, g)                                                                │  │
│  │                                                                                  │  │
│  │ Computation:                                                                     │  │
│  │   o_normalized = o / sqrt(mean(o²) + eps)                                       │  │
│  │   o_gated = o_normalized * swish(g)                                             │  │
│  │                                                                                  │  │
│  │ Output: [2,1024,4,128]                                                          │  │
│  └─────────────────────────────────────────────────────────────────────────────────┘  │
│                                                                                         │
│  ┌─────────────────────────────────────────────────────────────────────────────────┐  │
│  │ Final Reshape & Output Projection                                  ← L588-590   │  │
│  │ ─────────────────────────────────                                               │  │
│  │ o: [2,1024,4,128] → rearrange('b l h d -> b l (h d)') → [2,1024,512]            │  │
│  │                                                                                  │  │
│  │ o_proj: Linear(512 → 512), Params: 262K                                         │  │
│  │                                                                                  │  │
│  │ o = o_proj(o)                                                                   │  │
│  │ [2,1024,512] → [2,1024,512]                                                     │  │
│  └─────────────────────────────────────────────────────────────────────────────────┘  │
│                                                                                         │
└─────────────────────────────────────────────────────────────────────────────────────────┘
                                                                 │
                                                                 ▼
┌─────────────────────────────────────────────────────────────────────────────────────────┐
│  OUTPUT                                                             ← L592             │
│  Shape: [B=2, L=1024, D=512]                                                           │
│                                                                                         │
│  Return: (output, None, past_key_values, None)                                         │
│          # No router_logits (no sparse routing)                                        │
└─────────────────────────────────────────────────────────────────────────────────────────┘
```

---

## 维度变化流程表

| 阶段 | 操作 | Q维度 | K维度 | V维度 | 其他 |
|------|------|-------|-------|-------|------|
| 输入 | - | - | - | - | hidden:[2,1024,512], modality_ids:[2] |
| 投影 | Linear | [2,1024,256] | [2,1024,256] | [2,1024,512] | |
| 多头重排 | rearrange | [4,2,1024,64] | [4,2,1024,64] | [4,2,1024,128] | |
| 更新掩码 | _get_update_mask | - | - | - | mask:[3,2,1024,4] |
| Q共享+K扩展 | repeat+expert_proj | [3,4,2,1024,64] | [3,4,2,1024,64] | [3,4,2,1024,128] | Q用repeat(共享), K用专家投影 |
| 合并 | rearrange | [6,1024,256] | [6,1024,256] | [6,1024,512] | |
| 短卷积 | Conv1D | [6,1024,256] | [6,1024,256] | [6,1024,512] | |
| 拆分 | reshape | [3,2,1024,4,64] | [3,2,1024,4,64] | [3,2,1024,4,128] | |
| 应用掩码 | *mask | - | [3,2,1024,4,64] | [3,2,1024,4,128] | Q不变! |
| 合并头 | rearrange | [2,1024,12,64] | [2,1024,12,64] | [2,1024,12,128] | g,β:[2,1024,12] |
| Delta Rule | chunk_gated | - | - | - | o:[2,1024,12,128] |
| 拆分专家 | rearrange | - | - | - | o:[3,2,1024,4,128] |
| 加权聚合 | einsum | - | - | - | o:[2,1024,4,128] |
| 输出门控 | RMSNorm+Gate | - | - | - | o:[2,1024,4,128] |
| 最终投影 | Linear | - | - | - | o:[2,1024,512] |

---

## 参数量详细分解

```
┌────────────────────────────────────────────────────────────────────────────────┐
│                        Parameter Count (D=512, H=4, d=64, E=3)                 │
├────────────────────────────────────────────────────────────────────────────────┤
│                                                                                │
│  ┌─────────────────────────────────────────────────────────────────────────┐  │
│  │ Input Projections                                                        │  │
│  │ ─────────────────                                                       │  │
│  │ q_proj:  [512, 256]  = 131,072                                          │  │
│  │ k_proj:  [512, 256]  = 131,072                                          │  │
│  │ v_proj:  [512, 512]  = 262,144                                          │  │
│  │                        ─────────                                        │  │
│  │ Subtotal:              524,288 (0.52M)                                  │  │
│  └─────────────────────────────────────────────────────────────────────────┘  │
│                                                                                │
│  ┌─────────────────────────────────────────────────────────────────────────┐  │
│  │ Expert Projections (Per-Expert Per-Head)                                 │  │
│  │ ──────────────────────────────────                                      │  │
│  │ expert_k_proj_expand: [64, 64] × 3 experts × 4 heads = 49,152           │  │
│  │ (Q is SHARED - no per-expert Q projection)                               │  │
│  │                                                        ────────         │  │
│  │ Subtotal:                                             49,152 (0.05M)    │  │
│  └─────────────────────────────────────────────────────────────────────────┘  │
│                                                                                │
│  ┌─────────────────────────────────────────────────────────────────────────┐  │
│  │ Gating Parameters                                                        │  │
│  │ ──────────────────                                                      │  │
│  │ a_proj:   [512, 12] = 6,144                                             │  │
│  │ b_proj:   [512, 12] = 6,144                                             │  │
│  │ A_log:    [12]      = 12                                                │  │
│  │ dt_bias:  [12]      = 12                                                │  │
│  │                       ─────                                             │  │
│  │ Subtotal:             12,312 (0.01M)                                    │  │
│  └─────────────────────────────────────────────────────────────────────────┘  │
│                                                                                │
│  ┌─────────────────────────────────────────────────────────────────────────┐  │
│  │ Learnable Output Weights (NEW!)                                          │  │
│  │ ─────────────────────────────                                           │  │
│  │ output_weights: [3, 4] = 12                                             │  │
│  │                          ──                                              │  │
│  │ Subtotal:                12 (negligible)                                 │  │
│  └─────────────────────────────────────────────────────────────────────────┘  │
│                                                                                │
│  ┌─────────────────────────────────────────────────────────────────────────┐  │
│  │ Short Convolutions                                                       │  │
│  │ ──────────────────                                                      │  │
│  │ q_conv1d: kernel [256, 1, 4] + bias ≈ 1,280                             │  │
│  │ k_conv1d: kernel [256, 1, 4] + bias ≈ 1,280                             │  │
│  │ v_conv1d: kernel [512, 1, 4] + bias ≈ 2,560                             │  │
│  │                                       ─────                              │  │
│  │ Subtotal:                            ~5,120 (0.005M)                     │  │
│  └─────────────────────────────────────────────────────────────────────────┘  │
│                                                                                │
│  ┌─────────────────────────────────────────────────────────────────────────┐  │
│  │ Output Projections                                                       │  │
│  │ ───────────────────                                                     │  │
│  │ g_proj:  [512, 512] = 262,144                                           │  │
│  │ o_proj:  [512, 512] = 262,144                                           │  │
│  │ o_norm:  RMSNorm [128] ≈ 128                                            │  │
│  │                         ───────                                          │  │
│  │ Subtotal:               524,416 (0.52M)                                  │  │
│  └─────────────────────────────────────────────────────────────────────────┘  │
│                                                                                │
│  ═══════════════════════════════════════════════════════════════════════════  │
│  TOTAL PARAMETERS PER LAYER: ~1.11M                                           │
│  ═══════════════════════════════════════════════════════════════════════════  │
│                                                                                │
│  For 24-layer model:  1.11M × 24 = 26.6M parameters                           │
│  (excluding embeddings and LM head)                                           │
│                                                                                │
└────────────────────────────────────────────────────────────────────────────────┘
```

---

## 多模态专家激活模式可视化

```
┌─────────────────────────────────────────────────────────────────────────────────────────┐
│  MULTIMODAL EXPERT ACTIVATION PATTERN                                                   │
│  ═══════════════════════════════════════════════════════════════════════════════════   │
│                                                                                         │
│  Configuration: E=3 (Shared + Text + Vision), modality_ids = [0, 1] (text, vision)     │
│                                                                                         │
│                                                                                         │
│  STATE UPDATE Pattern (based on modality_ids):                                         │
│  ─────────────────────────────────────────────                                         │
│                                                                                         │
│  Expert Index:       0 (Shared)      1 (Text)       2 (Vision)                         │
│                          │               │               │                              │
│                          ▼               ▼               ▼                              │
│                    ┌──────────┐    ┌──────────┐    ┌──────────┐                         │
│  Batch 0 (text):   │ ████████ │    │ ████████ │    │          │                         │
│  modality_id=0     │ UPDATED  │    │ UPDATED  │    │ NOT UPD  │                         │
│                    └──────────┘    └──────────┘    └──────────┘                         │
│                                                                                         │
│                    ┌──────────┐    ┌──────────┐    ┌──────────┐                         │
│  Batch 1 (vision): │ ████████ │    │          │    │ ████████ │                         │
│  modality_id=1     │ UPDATED  │    │ NOT UPD  │    │ UPDATED  │                         │
│                    └──────────┘    └──────────┘    └──────────┘                         │
│                                                                                         │
│                                                                                         │
│  OUTPUT QUERY Pattern (ALL states queried!):                                           │
│  ─────────────────────────────────────────────                                         │
│                                                                                         │
│                    ┌──────────┐    ┌──────────┐    ┌──────────┐                         │
│  Batch 0 (text):   │ ████████ │    │ ████████ │    │ ████████ │                         │
│                    │ q·S_sh   │    │ q·S_txt  │    │ q·S_vis  │                         │
│                    │ (fresh)  │    │ (fresh)  │    │(history) │                         │
│                    └──────────┘    └──────────┘    └──────────┘                         │
│                          │               │               │                              │
│                          └───────────────┼───────────────┘                              │
│                                          ▼                                              │
│                              ┌─────────────────────┐                                    │
│                              │  Weighted Sum        │                                   │
│                              │  w_sh×o_sh + w_txt× │                                   │
│                              │  o_txt + w_vis×o_vis│                                   │
│                              └─────────────────────┘                                    │
│                                                                                         │
│                                                                                         │
│  KEY INSIGHT:                                                                          │
│  ────────────                                                                          │
│  ┌─────────────────────────────────────────────────────────────────────────────────┐  │
│  │ Even when processing TEXT, the model can access VISION state (historical)       │  │
│  │ Even when processing VISION, the model can access TEXT state (historical)       │  │
│  │                                                                                  │  │
│  │ This enables:                                                                    │  │
│  │   • Cross-modal information sharing                                              │  │
│  │   • Multimodal context awareness                                                 │  │
│  │   • Unified representation learning                                              │  │
│  └─────────────────────────────────────────────────────────────────────────────────┘  │
│                                                                                         │
└─────────────────────────────────────────────────────────────────────────────────────────┘
```

---

## 交错式多模态模式 (Interleaved Mode)

> 新增功能：支持同一序列内图文交错的多模态输入处理

### 两种模态路由模式对比

```
┌─────────────────────────────────────────────────────────────────────────────────────────┐
│                     序列级 vs Token级 模态路由对比                                        │
├─────────────────────────────────────────────────────────────────────────────────────────┤
│                                                                                         │
│  ┌─────────────────────────────────────┐    ┌─────────────────────────────────────────┐│
│  │    方案A: 序列级 (Sequence-Level)    │    │    方案B: Token级 (Interleaved Mode)   ││
│  │         interleaved_mode=False       │    │         interleaved_mode=True          ││
│  │                                      │    │                                        ││
│  │  modality_ids: [B]                   │    │  modality_ids: [B, L]                  ││
│  │                                      │    │                                        ││
│  │  ┌─────────────────────────────────┐│    │  ┌─────────────────────────────────────┐││
│  │  │ Batch 0: 全部是文本              ││    │  │ Batch 0: [bos][img][img][txt][txt]  │││
│  │  │ [txt][txt][txt][txt][txt][txt]  ││    │  │ modality: [-1] [1] [1] [0] [0]      │││
│  │  │ modality_id = 0                 ││    │  │                                     │││
│  │  └─────────────────────────────────┘│    │  │ Batch 1: [bos][txt][txt][img][img]  │││
│  │  ┌─────────────────────────────────┐│    │  │ modality: [-1] [0] [0] [1] [1]      │││
│  │  │ Batch 1: 全部是图像              ││    │  └─────────────────────────────────────┘││
│  │  │ [img][img][img][img][img][img]  ││    │                                        ││
│  │  │ modality_id = 1                 ││    │  适用场景:                              ││
│  │  └─────────────────────────────────┘│    │  • 图文交错对话 (LLaVA, Qwen-VL)       ││
│  │                                      │    │  • 多轮视觉问答                        ││
│  │  适用场景:                           │    │  • 单序列内混合多模态数据              ││
│  │  • 纯文本或纯图像批次               │    │                                        ││
│  │  • 预训练阶段分离模态               │    │                                        ││
│  └─────────────────────────────────────┘    └─────────────────────────────────────────┘│
│                                                                                         │
└─────────────────────────────────────────────────────────────────────────────────────────┘
```

### 模态ID常量定义

```
┌─────────────────────────────────────────────────────────────────────────────────────────┐
│  MODALITY ID CONSTANTS                                              ← layer.py L27-29   │
│  ═══════════════════════════════════════════════════════════════════════════════════   │
│                                                                                         │
│  ┌─────────────────────────────────────────────────────────────────────────────────┐  │
│  │ Constant           │ Value │ 含义                │ 激活的专家                    │  │
│  │ ───────────────────┼───────┼─────────────────────┼─────────────────────────────  │  │
│  │ MODALITY_TEXT      │   0   │ 文本token           │ Expert 0 (Shared) + Expert 1 │  │
│  │ MODALITY_VISION    │   1   │ 图像token           │ Expert 0 (Shared) + Expert 2 │  │
│  │ MODALITY_SHARED    │  -1   │ 特殊token           │ Expert 0 (Shared) 仅         │  │
│  │                    │       │ (bos/eos/pad/等)    │                              │  │
│  └─────────────────────────────────────────────────────────────────────────────────┘  │
│                                                                                         │
│  特殊token处理说明:                                                                     │
│  ─────────────────                                                                     │
│  • bos_token_id: 句子开始符，标记为 MODALITY_SHARED (-1)                               │
│  • eos_token_id: 句子结束符，标记为 MODALITY_SHARED (-1)                               │
│  • pad_token_id: 填充符，标记为 MODALITY_SHARED (-1)                                   │
│  • image_token_id: 图像占位符 (如 <image>)，标记为 MODALITY_VISION (1)                 │
│                                                                                         │
│  MODALITY_SHARED 的设计意图:                                                           │
│  • 特殊token不应偏向任何特定模态                                                       │
│  • 仅更新共享状态，保持模态专用状态不变                                                │
│  • 减少特殊token对模态专用表示的干扰                                                   │
│                                                                                         │
└─────────────────────────────────────────────────────────────────────────────────────────┘
```

### 从 input_ids 自动推断模态ID

```
┌─────────────────────────────────────────────────────────────────────────────────────────┐
│  AUTO-INFER MODALITY IDS FROM INPUT_IDS                            ← layer.py L227-268  │
│  ═══════════════════════════════════════════════════════════════════════════════════   │
│                                                                                         │
│  ┌─────────────────────────────────────────────────────────────────────────────────┐  │
│  │ 推断流程 (_infer_modality_ids 方法):                                            │  │
│  │                                                                                  │  │
│  │  input_ids = [1, 32000, 32000, 32000, 100, 101, 102, 2, 0, 0, 0, 0, ...]        │  │
│  │               ↓    ↓     ↓     ↓     ↓    ↓    ↓   ↓  ↓  ↓  ↓  ↓               │  │
│  │              bos  img   img   img   txt  txt  txt eos pad pad pad pad           │  │
│  │               ↓    ↓     ↓     ↓     ↓    ↓    ↓   ↓  ↓  ↓  ↓  ↓               │  │
│  │  modality  = [-1,  1,    1,    1,    0,   0,   0, -1, -1, -1, -1, -1, ...]      │  │
│  │                                                                                  │  │
│  │  步骤:                                                                          │  │
│  │  1. 初始化全部为 MODALITY_TEXT (0)                                              │  │
│  │  2. 检测 image_token_id → 标记为 MODALITY_VISION (1)                            │  │
│  │  3. 检测 bos/eos/pad_token_id → 标记为 MODALITY_SHARED (-1)                     │  │
│  │                                                                                  │  │
│  └─────────────────────────────────────────────────────────────────────────────────┘  │
│                                                                                         │
│  配置示例 (LLaVA 风格):                                                                │
│  ─────────────────────                                                                 │
│  config = MultimodalGatedDeltaNetConfig(                                              │
│      interleaved_mode=True,                                                           │
│      image_token_id=32000,      # <image> token ID                                    │
│      bos_token_id=1,            # <s> token ID                                        │
│      eos_token_id=2,            # </s> token ID                                       │
│      pad_token_id=0,            # <pad> token ID                                      │
│  )                                                                                     │
│                                                                                         │
└─────────────────────────────────────────────────────────────────────────────────────────┘
```

### 交错模式下的更新掩码生成

```
┌─────────────────────────────────────────────────────────────────────────────────────────┐
│  TOKEN-LEVEL UPDATE MASK GENERATION                                ← layer.py L270-326  │
│  ═══════════════════════════════════════════════════════════════════════════════════   │
│                                                                                         │
│  示例序列: [bos, img, img, shared, txt, txt, txt, eos]                                 │
│  modality:  -1    1    1    -1      0    0    0   -1                                   │
│                                                                                         │
│  ┌─────────────────────────────────────────────────────────────────────────────────┐  │
│  │ Token位置:     0     1     2     3     4     5     6     7                      │  │
│  │ Modality ID:  -1     1     1    -1     0     0     0    -1                      │  │
│  │ ───────────────────────────────────────────────────────────────────────────────  │  │
│  │                                                                                  │  │
│  │ Expert 0 (Shared):                                                              │  │
│  │ update_mask:   1     1     1     1     1     1     1     1    ← 始终激活        │  │
│  │               ███   ███   ███   ███   ███   ███   ███   ███                     │  │
│  │                                                                                  │  │
│  │ Expert 1 (Text):                                                                │  │
│  │ update_mask:   0     0     0     0     1     1     1     0    ← modality==0 时  │  │
│  │                                       ███   ███   ███                           │  │
│  │                                                                                  │  │
│  │ Expert 2 (Vision):                                                              │  │
│  │ update_mask:   0     1     1     0     0     0     0     0    ← modality==1 时  │  │
│  │                     ███   ███                                                   │  │
│  │                                                                                  │  │
│  └─────────────────────────────────────────────────────────────────────────────────┘  │
│                                                                                         │
│  关键特性:                                                                             │
│  ─────────                                                                             │
│  • Expert 0 (Shared): 所有位置都更新，积累全局信息                                     │
│  • Expert 1 (Text): 仅在文本token位置更新，保持文本专用表示                            │
│  • Expert 2 (Vision): 仅在图像token位置更新，保持视觉专用表示                          │
│  • MODALITY_SHARED (-1): 只更新共享专家，不干扰模态专用状态                            │
│                                                                                         │
│  输出聚合 (不变):                                                                      │
│  ────────────────                                                                      │
│  • Q 仍然不被掩码，所有位置都能查询所有三个状态                                        │
│  • 输出仍然是三个专家的加权和: o = w_sh×o_sh + w_txt×o_txt + w_vis×o_vis              │
│                                                                                         │
└─────────────────────────────────────────────────────────────────────────────────────────┘
```

### 交错模式专家激活可视化

```
┌─────────────────────────────────────────────────────────────────────────────────────────┐
│  INTERLEAVED MODE EXPERT ACTIVATION VISUALIZATION                                       │
│  ═══════════════════════════════════════════════════════════════════════════════════   │
│                                                                                         │
│  输入序列: "<bos> <img> <img> <img> Hello world ! <eos>"                               │
│  Token ID:   1   32000 32000 32000  100   101  102   2                                 │
│                                                                                         │
│  ┌─────────────────────────────────────────────────────────────────────────────────┐  │
│  │                        Token Position (Time →)                                  │  │
│  │  Position:    0      1      2      3      4      5      6      7                │  │
│  │  Token:     <bos>  <img>  <img>  <img>  Hello  world    !    <eos>             │  │
│  │  Modality:   -1     1      1      1      0      0      0     -1                │  │
│  │  ─────────────────────────────────────────────────────────────────────────────  │  │
│  │                                                                                  │  │
│  │  S_shared   ┌────┐ ┌────┐ ┌────┐ ┌────┐ ┌────┐ ┌────┐ ┌────┐ ┌────┐           │  │
│  │  (Expert 0) │ ██ │→│ ██ │→│ ██ │→│ ██ │→│ ██ │→│ ██ │→│ ██ │→│ ██ │           │  │
│  │             └────┘ └────┘ └────┘ └────┘ └────┘ └────┘ └────┘ └────┘           │  │
│  │             update update update update update update update update           │  │
│  │                                                                                  │  │
│  │  S_text     ┌────┐ ┌────┐ ┌────┐ ┌────┐ ┌────┐ ┌────┐ ┌────┐ ┌────┐           │  │
│  │  (Expert 1) │    │→│    │→│    │→│    │→│ ██ │→│ ██ │→│ ██ │→│    │           │  │
│  │             └────┘ └────┘ └────┘ └────┘ └────┘ └────┘ └────┘ └────┘           │  │
│  │             skip   skip   skip   skip  update update update  skip             │  │
│  │                                                                                  │  │
│  │  S_vision   ┌────┐ ┌────┐ ┌────┐ ┌────┐ ┌────┐ ┌────┐ ┌────┐ ┌────┐           │  │
│  │  (Expert 2) │    │→│ ██ │→│ ██ │→│ ██ │→│    │→│    │→│    │→│    │           │  │
│  │             └────┘ └────┘ └────┘ └────┘ └────┘ └────┘ └────┘ └────┘           │  │
│  │             skip  update update update  skip   skip   skip   skip             │  │
│  │                                                                                  │  │
│  │  ─────────────────────────────────────────────────────────────────────────────  │  │
│  │                                                                                  │  │
│  │  Output at position 5 ("world"):                                                │  │
│  │                                                                                  │  │
│  │    o_5 = w_sh × (q_5 · S_shared) +     ← 包含 pos 0-5 的全部信息               │  │
│  │          w_txt × (q_5 · S_text) +      ← 包含 pos 4-5 的文本信息               │  │
│  │          w_vis × (q_5 · S_vision)      ← 包含 pos 1-3 的图像信息 (历史)        │  │
│  │                                                                                  │  │
│  │  → 处理 "world" 时可以同时访问文本和图像的上下文！                              │  │
│  │                                                                                  │  │
│  └─────────────────────────────────────────────────────────────────────────────────┘  │
│                                                                                         │
└─────────────────────────────────────────────────────────────────────────────────────────┘
```

---

## 状态更新与输出聚合机制对比

```
┌─────────────────────────────────────────────────────────────────────────────────────────┐
│          MoE (Sparse Routing) vs MultimodalGatedDeltaNet Comparison                     │
├─────────────────────────────────────────────────────────────────────────────────────────┤
│                                                                                         │
│  ┌───────────────────────────────────┐    ┌───────────────────────────────────────┐    │
│  │       MoE (Sparse Routing)        │    │    MultimodalGatedDeltaNet            │    │
│  │                                   │    │                                       │    │
│  │  • Dynamic routing per token      │    │  • Fixed routing per sequence         │    │
│  │  • TopK selection (e.g., K=2)     │    │  • Modality-based selection           │    │
│  │  • Sparse mask on Q, K, V         │    │  • Sparse mask on K, V only           │    │
│  │  • Only selected experts output   │    │  • ALL experts contribute output      │    │
│  │                                   │    │                                       │    │
│  │  ┌─────────────────────────────┐  │    │  ┌─────────────────────────────────┐  │    │
│  │  │ Token → Router → TopK      │  │    │  │ Sequence → modality_id         │  │    │
│  │  │         ↓                   │  │    │  │            ↓                    │  │    │
│  │  │ Q,K,V masked for selected  │  │    │  │ K,V masked, Q NOT masked        │  │    │
│  │  │         ↓                   │  │    │  │            ↓                    │  │    │
│  │  │ Output = Σ w_i × o_i       │  │    │  │ Output = Σ w_e × (q·S_e)        │  │    │
│  │  │ (only K active experts)    │  │    │  │ (ALL E experts)                 │  │    │
│  │  └─────────────────────────────┘  │    │  └─────────────────────────────────┘  │    │
│  │                                   │    │                                       │    │
│  │  Pros:                            │    │  Pros:                                │    │
│  │  ✓ Computational efficiency       │    │  ✓ Cross-modal information sharing   │    │
│  │  ✓ Scalable to many experts       │    │  ✓ Simple modality-based routing     │    │
│  │                                   │    │  ✓ Learnable output weights           │    │
│  │  Cons:                            │    │                                       │    │
│  │  × No cross-expert interaction    │    │  Cons:                                │    │
│  │  × Complex routing overhead       │    │  × Fixed number of experts (3)        │    │
│  └───────────────────────────────────┘    └───────────────────────────────────────┘    │
│                                                                                         │
│  ═══════════════════════════════════════════════════════════════════════════════════   │
│                                                                                         │
│  Mathematical Comparison:                                                               │
│  ────────────────────────                                                              │
│                                                                                         │
│  MoE:                                                                                  │
│    o = Σ_{i ∈ TopK(router(x))} w_i × Expert_i(x)                                       │
│        (sum over K selected experts)                                                   │
│                                                                                         │
│  MultimodalGatedDeltaNet:                                                              │
│    State Update:  S_e^{t+1} = g_e·S_e^t + β_e·k_e^T⊗v_e  (if update_mask[e]=1)        │
│    Output:        o = Σ_{e=0}^{2} w_e × (q · S_e)        (always all 3 experts)        │
│                                                                                         │
│  Key Difference:                                                                        │
│  • MoE: Experts are functions applied to current input                                 │
│  • Ours: Experts are persistent STATES that accumulate information                     │
│                                                                                         │
└─────────────────────────────────────────────────────────────────────────────────────────┘
```

---

## 代码结构与文件对应

```
┌─────────────────────────────────────────────────────────────────────────────────────────┐
│                              Code Structure Mapping                                     │
├─────────────────────────────────────────────────────────────────────────────────────────┤
│                                                                                         │
│  /public/liguoqi/wom/DendAttn/models/src/                                              │
│  │                                                                                      │
│  ├── mob_gated_deltanet_moe/                ◄─── 参考实现 (稀疏路由 MoE)                 │
│  │   ├── __init__.py                                                                   │
│  │   ├── configuration_mob_gated_deltanet_moe.py                                       │
│  │   ├── layer.py                            MobGatedDeltaNetMoE Layer                 │
│  │   │   ├── sparse()          [L241-273]    稀疏路由计算                              │
│  │   │   └── forward()         [L276-443]    前向传播                                  │
│  │   └── modeling_mob_gated_deltanet_moe.py                                            │
│  │                                                                                      │
│  └── multimodal_gated_deltanet/             ◄─── 新实现 (多模态三专家)                  │
│      ├── __init__.py                            模块注册                               │
│      ├── configuration_multimodal_gated_deltanet.py                                    │
│      │   └── MultimodalGatedDeltaNetConfig  配置类                                     │
│      │       ├── num_modalities = 2         模态数量                                   │
│      │       ├── modality_names             ['text', 'vision']                        │
│      │       ├── num_experts = 3            1 shared + 2 modality                     │
│      │       ├── interleaved_mode = False   交错模式开关 (NEW)                        │
│      │       └── image_token_id = None      图像token ID (NEW)                        │
│      │                                                                                 │
│      ├── layer.py                               核心层实现                             │
│      │   └── MultimodalGatedDeltaNet                                                  │
│      │       ├── Constants                                                            │
│      │       │   ├── MODALITY_TEXT = 0      [L27]                                     │
│      │       │   ├── MODALITY_VISION = 1    [L28]                                     │
│      │       │   └── MODALITY_SHARED = -1   [L29] (NEW - 特殊token)                   │
│      │       │                                                                        │
│      │       ├── __init__()             [L87-225]                                     │
│      │       │   ├── q_proj, k_proj, v_proj  共享投影                                 │
│      │       │   ├── expert_k_proj_expand    专家K扩展投影 (Q共享,无专家Q投影)        │
│      │       │   ├── output_weights          可学习聚合权重                           │
│      │       │   ├── b_proj, a_proj, A_log   门控参数                                 │
│      │       │   └── interleaved_mode 相关参数 (NEW)                                  │
│      │       │                                                                        │
│      │       ├── _infer_modality_ids()  [L227-268] (NEW)                              │
│      │       │   └── 从 input_ids 自动推断 modality_ids                               │
│      │       │                                                                        │
│      │       ├── _get_update_mask()     [L270-326]                                    │
│      │       │   └── 支持 [B] 和 [B,L] 两种格式的 modality_ids                        │
│      │       │                                                                        │
│      │       ├── _get_output_weights()  [L328-337]                                    │
│      │       │   └── softmax 归一化可学习权重                                         │
│      │       │                                                                        │
│      │       └── forward()              [L339-592]                                    │
│      │           ├── 模态ID处理         [L379-388] (支持自动推断)                     │
│      │           ├── 基础投影           [L400-403]                                    │
│      │           ├── 更新掩码生成       [L410-413]                                    │
│      │           ├── Q共享+K专家扩展    [L415-438] (Q用repeat, K用专家投影)          │
│      │           ├── 短卷积             [L445-466]                                    │
│      │           ├── 应用更新掩码       [L473-478]  (K,V masked, Q not!)             │
│      │           ├── 门控参数           [L480-495]                                    │
│      │           ├── Delta Rule 计算    [L526-550]                                    │
│      │           ├── 可学习权重聚合     [L564-567]                                    │
│      │           └── 输出投影           [L581-590]                                    │
│      │                                                                                 │
│      ├── modeling_multimodal_gated_deltanet.py  模型定义                              │
│      │   ├── MultimodalGatedDeltaNetBlock       Block定义                             │
│      │   ├── MultimodalGatedDeltaNetModel       基础模型                              │
│      │   └── MultimodalGatedDeltaNetForCausalLM 因果语言模型                          │
│      │                                                                                 │
│      ├── test_multimodal.py                     基础测试脚本                          │
│      │                                                                                 │
│      └── test_interleaved.py                    交错模式测试脚本 (NEW)                │
│          ├── test_sequence_level_backward_compatible()  序列级向后兼容测试            │
│          ├── test_token_level_explicit()                Token级显式测试               │
│          ├── test_auto_infer_from_input_ids()           自动推断测试                  │
│          ├── test_update_mask_token_level()             更新掩码测试                  │
│          ├── test_gradient_flow()                       梯度流测试                    │
│          └── test_mixed_batch()                         混合批次测试                  │
│                                                                                         │
│  Key Dependencies:                                                                      │
│  ├── fla.ops.gated_delta_rule                                                          │
│  │   └── chunk_gated_delta_rule()        Chunk模式 Delta Rule                          │
│  ├── fla.modules                                                                       │
│  │   ├── ShortConvolution                短卷积层                                      │
│  │   └── FusedRMSNormSwishGate          融合门控归一化                                 │
│  └── einops                                                                            │
│      ├── rearrange()                     张量重排                                      │
│      └── repeat()                        张量复制                                      │
│                                                                                         │
└─────────────────────────────────────────────────────────────────────────────────────────┘
```

---

## 使用示例

### 序列级模态路由 (默认模式)

```python
from multimodal_gated_deltanet import (
    MultimodalGatedDeltaNetConfig,
    MultimodalGatedDeltaNetForCausalLM
)
import torch

# 创建配置
config = MultimodalGatedDeltaNetConfig(
    hidden_size=512,
    num_heads=4,
    head_dim=64,
    expand_v=2,
    num_hidden_layers=24,
    vocab_size=32000,
    num_modalities=2,      # text + vision
)

# 创建模型
model = MultimodalGatedDeltaNetForCausalLM(config).cuda()

# 准备输入
batch_size, seq_len = 2, 1024
input_ids = torch.randint(0, 32000, (batch_size, seq_len)).cuda()

# 指定模态类型 (序列级)
modality_ids = torch.tensor([0, 1]).cuda()  # batch 0 是 text, batch 1 是 vision

# 前向传播
outputs = model(
    input_ids=input_ids,
    modality_ids=modality_ids,
)

# 输出
print(f"Logits shape: {outputs.logits.shape}")  # [2, 1024, 32000]
```

### 交错式多模态模式 (Interleaved Mode)

```python
from multimodal_gated_deltanet import (
    MultimodalGatedDeltaNetConfig,
    MultimodalGatedDeltaNetForCausalLM
)
from multimodal_gated_deltanet.layer import MODALITY_TEXT, MODALITY_VISION, MODALITY_SHARED
import torch

# 创建配置 - 启用交错模式
config = MultimodalGatedDeltaNetConfig(
    hidden_size=512,
    num_heads=4,
    head_dim=64,
    expand_v=2,
    num_hidden_layers=24,
    vocab_size=32000,
    num_modalities=2,
    # 交错模式配置
    interleaved_mode=True,
    image_token_id=32000,     # <image> token ID
    bos_token_id=1,           # <s> token ID
    eos_token_id=2,           # </s> token ID
    pad_token_id=0,           # <pad> token ID
)

# 创建模型
model = MultimodalGatedDeltaNetForCausalLM(config).cuda()

# ============ 方式1: 自动从 input_ids 推断 (推荐) ============
batch_size, seq_len = 2, 128
# 构造交错的输入序列: [bos, img, img, img, text, text, ..., eos]
input_ids = torch.full((batch_size, seq_len), 100, dtype=torch.long).cuda()
input_ids[:, 0] = 1           # bos
input_ids[0, 1:4] = 32000     # batch 0: 图像在前
input_ids[1, 50:53] = 32000   # batch 1: 图像在中间
input_ids[:, -1] = 2          # eos

# 前向传播 - 自动推断 modality_ids
outputs = model(input_ids=input_ids)
print(f"Auto-infer logits shape: {outputs.logits.shape}")  # [2, 128, 32000]


# ============ 方式2: 显式传入 token 级 modality_ids ============
modality_ids = torch.zeros(batch_size, seq_len, dtype=torch.long).cuda()  # 默认文本
modality_ids[:, 0] = MODALITY_SHARED      # bos
modality_ids[0, 1:4] = MODALITY_VISION    # batch 0 图像位置
modality_ids[1, 50:53] = MODALITY_VISION  # batch 1 图像位置
modality_ids[:, -1] = MODALITY_SHARED     # eos

outputs = model(input_ids=input_ids, modality_ids=modality_ids)
print(f"Explicit logits shape: {outputs.logits.shape}")  # [2, 128, 32000]


# ============ 方式3: 直接使用 Layer (用于测试) ============
from multimodal_gated_deltanet.layer import MultimodalGatedDeltaNet

layer = MultimodalGatedDeltaNet(
    hidden_size=256,
    num_heads=4,
    head_dim=32,
    expand_v=2,
    interleaved_mode=True,
    image_token_id=32000,
    bos_token_id=1,
    eos_token_id=2,
    pad_token_id=0,
).cuda()

hidden_states = torch.randn(2, 128, 256).cuda()
output, _, _, _ = layer(hidden_states, input_ids=input_ids)
print(f"Layer output shape: {output.shape}")  # [2, 128, 256]
```
