# MoEUT 详细架构示意图

> 配置: B=2, L=1024, D=1024, H=8, d=128, E=128, Es_ffn=128, Es_att=10, K_ffn=16, K_att=2, group_size=2
>
> 代码行号标注格式: `← Lxxx` 表示对应文件的第 xxx 行

---

## 完整架构总览图

```
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃                                    MoEUT Layer                                        ┃
┃                (Mixture-of-Experts Universal Transformer with Entropy Regularization) ┃
┃                                                                                        ┃
┃  代码文件: llm_effective_depth-master/training/layers/moeut.py                        ┃
┃  主类: MoEUT                                                                          ┃
┗━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┛
                                           │
                                           ▼
┌─────────────────────────────────────────────────────────────────────────────────────────┐
│  UNIVERSAL TRANSFORMER STRUCTURE                                     ← L38-55           │
│  ═══════════════════════════════════════════════════════════════════════════════════    │
│                                                                                         │
│  Configuration: n_layers=18, group_size=2                                              │
│  Physical Layers: 18 / 2 = 9                                                           │
│  Logical Layers: 18 (repeat 9 times)                                                   │
│                                                                                         │
│  ┌─────────────────────────────────────────────────────────────────────────────────┐  │
│  │ Parameter Sharing Pattern:                                                       │  │
│  │                                                                                  │  │
│  │  Physical Layer 0  ─┐                                                           │  │
│  │  Physical Layer 1  ─┤ Used in iterations 0, 2, 4, 6, 8                         │  │
│  │                     │ (9 iterations total)                                      │  │
│  │  Logical Layers: 0, 2, 4, 6, 8, 10, 12, 14, 16                                 │  │
│  │                                                                                  │  │
│  └─────────────────────────────────────────────────────────────────────────────────┘  │
│                                                                                         │
└─────────────────────────────────────────────────────────────────────────────────────────┘
                                           │
                                           ▼
┌─────────────────────────────────────────────────────────────────────────────────────────┐
│  INPUT: x                                                            ← L317             │
│  Shape: [B=2, L=1024, D=1024]                                                          │
│  Memory: 8.4 MB (FP32)                                                                 │
└─────────────────────────────────────────────────────────────────────────────────────────┘
                                           │
                                           ▼
┌─────────────────────────────────────────────────────────────────────────────────────────┐
│  PRE-LAYER NORMALIZATION                                             ← L318             │
│  ═══════════════════════════════════════════════════════════════════════════════════    │
│                                                                                         │
│  xnorm = self.ln1(x)                                                                   │
│  [2, 1024, 1024]                                                                       │
│                                                                                         │
└─────────────────────────────────────────────────────────────────────────────────────────┘
                                           │
          ┌────────────────────────────────┴────────────────────────────────┐
          │                                                                  │
          ▼                                                                  ▼
┌───────────────────────────────────────┐              ┌───────────────────────────────────┐
│     MOE ATTENTION MODULE              │              │         RESIDUAL PATH             │
│  ┌─────────────────────────────────┐  │              │                                   │
│  │ SwitchHeadRope                  │  │              │  x (unchanged)                    │
│  │                      ← L319-320 │  │              │  [2, 1024, 1024]                  │
│  └─────────────────────────────────┘  │              │                                   │
│            │                           │              └───────────────────────────────────┘
│            ▼                           │                              │
│  ┌─────────────────────────────────┐  │                              │
│  │ Q, K, V Projections             │  │                              │
│  │ Q: Linear(1024 → 1024)          │  │                              │
│  │ K: Linear(1024 → 1024)          │  │                              │
│  │ V: Linear(1024 → proj_size×H)   │  │                              │
│  └─────────────────────────────────┘  │                              │
│            │                           │                              │
│            ▼                           │                              │
│  ┌─────────────────────────────────┐  │                              │
│  │ Per-Head Expert Selection       │  │                              │
│  │                                 │  │                              │
│  │ For each head h ∈ [0, 7]:      │  │                              │
│  │   sel = sigmoid(linear(x))     │  │                              │
│  │   selected = topk(sel, k=2)    │  │                              │
│  │                                 │  │                              │
│  │ V experts: 10 experts/head     │  │                              │
│  │ O experts: 10 experts/head     │  │                              │
│  │ Top-K: 2 experts selected      │  │                              │
│  └─────────────────────────────────┘  │                              │
│            │                           │                              │
│            ▼                           │                              │
│  ┌─────────────────────────────────┐  │                              │
│  │ RoPE + Attention Computation    │  │                              │
│  │ with Selected Experts           │  │                              │
│  │                                 │  │                              │
│  │ Output: [2, 1024, 1024]         │  │                              │
│  └─────────────────────────────────┘  │                              │
│            │                           │                              │
└────────────┼───────────────────────────┘                              │
             │                                                          │
             └──────────────────────┬───────────────────────────────────┘
                                    │
                                    ▼
┌─────────────────────────────────────────────────────────────────────────────────────────┐
│  RESIDUAL CONNECTION + DROPOUT                                       ← L321             │
│  ═══════════════════════════════════════════════════════════════════════════════════    │
│                                                                                         │
│  x = x + strength * self.drop(att)                                                     │
│  [2, 1024, 1024]                                                                       │
│                                                                                         │
│  strength: 控制每层贡献的权重（默认=1）                                                  │
│                                                                                         │
└─────────────────────────────────────────────────────────────────────────────────────────┘
                                    │
                                    ▼
┌─────────────────────────────────────────────────────────────────────────────────────────┐
│  PRE-FFN NORMALIZATION                                               ← L323             │
│  ═══════════════════════════════════════════════════════════════════════════════════    │
│                                                                                         │
│  upd_in = self.ln2(x)                                                                  │
│  [2, 1024, 1024]                                                                       │
│                                                                                         │
└─────────────────────────────────────────────────────────────────────────────────────────┘
                                    │
                                    ▼
┌─────────────────────────────────────────────────────────────────────────────────────────┐
│  MOE FFN MODULE (SigmaMoE)                                           ← L323             │
│  ═══════════════════════════════════════════════════════════════════════════════════    │
│                                                                                         │
│  ┌─────────────────────────────────────────────────────────────────────────────────┐  │
│  │ EXPERT SELECTION MECHANISM                                       ← L86-107       │  │
│  │ ═══════════════════════════════════════════════════════════════════════════════ │  │
│  │                                                                                  │  │
│  │  Input: t = [B=2, L=1024, D=1024]                                               │  │
│  │    ↓                                                                             │  │
│  │  sel_raw = linear(t, expert_sel)   # [2, 1024, 128]              ← L86          │  │
│  │    ↓                                                                             │  │
│  │  sel = sigmoid(sel_raw)             # Independent scoring!       ← L87          │  │
│  │    ↓                                                                             │  │
│  │  ┌─────────────────────────────────────────────────────────────────────────┐   │  │
│  │  │ Expert Dropout (Training only)                               ← L90-92    │   │  │
│  │  │                                                                          │   │  │
│  │  │ if training and expert_dropout > 0:                                     │   │  │
│  │  │     mask = rand_like(sel) < expert_dropout                              │   │  │
│  │  │     sel = sel.masked_fill(mask, -inf)                                   │   │  │
│  │  │                                                                          │   │  │
│  │  │ Purpose: Force diversity, prevent expert collapse                       │   │  │
│  │  └─────────────────────────────────────────────────────────────────────────┘   │  │
│  │    ↓                                                                             │  │
│  │  sel_val, sel_index = topk(sel, k=16)  # Select top-16         ← L94          │  │
│  │    ↓                                                                             │  │
│  │  routing_weights: [2, 1024, 16]  # Weights of selected experts                 │  │
│  │  routing_indices: [2, 1024, 16]  # Indices of selected experts                 │  │
│  │                                                                                  │  │
│  └─────────────────────────────────────────────────────────────────────────────────┘  │
│                                                                                         │
│  ┌─────────────────────────────────────────────────────────────────────────────────┐  │
│  │ SPARSE EXPERT COMPUTATION (cvmm)                                ← L99-106       │  │
│  │ ═══════════════════════════════════════════════════════════════════════════════ │  │
│  │                                                                                  │  │
│  │  Step 1: Prepare selection indices for GPU                      ← L96          │  │
│  │  ────────────────────────────────────────────────────────────────────────────   │  │
│  │  sel_indices = cvmm_prepare_sel2(routing_indices, routing_weights)             │  │
│  │  • Sorts indices for efficient GPU memory access                               │  │
│  │  • Stores reduction weights for weighted aggregation                           │  │
│  │                                                                                  │  │
│  │  Step 2: Up Projection (only selected experts!)                 ← L99          │  │
│  │  ────────────────────────────────────────────────────────────────────────────   │  │
│  │  keys: [n_experts=128, dmodel=1024, expert_size=128]                           │  │
│  │                                                                                  │  │
│  │  scores = cvmm(t, sel_indices, keys)                                           │  │
│  │  • Input: [2, 1024, 1024]                                                      │  │
│  │  • Only computes 16 out of 128 experts                                         │  │
│  │  • Output: [2, 1024, 16, 128]  (per-token, per-expert)                        │  │
│  │  • Speedup: 128/16 = 8× faster!                                               │  │
│  │    ↓                                                                             │  │
│  │  scores = activation(scores)    # ReLU or GELU                 ← L100         │  │
│  │                                                                                  │  │
│  │  Step 3: Down Projection with weighted aggregation              ← L103-106     │  │
│  │  ────────────────────────────────────────────────────────────────────────────   │  │
│  │  values: [n_experts=128, expert_size=128, dmodel=1024]                         │  │
│  │                                                                                  │  │
│  │  sel_indices.reduction_weight = routing_weights  # Set weights ← L103         │  │
│  │  out = cvmm(scores, sel_indices, values)                       ← L106         │  │
│  │  • Computes: Σ_{i=1}^{16} weight_i × expert_i(x)                              │  │
│  │  • Output: [2, 1024, 1024]                                                     │  │
│  │                                                                                  │  │
│  │  ┌─────────────────────────────────────────────────────────────────────────┐   │  │
│  │  │                     cvmm Triton Kernel                                   │   │  │
│  │  │  ═══════════════════════════════════════════════════════════════════   │   │  │
│  │  │                                                                          │   │  │
│  │  │  @triton.jit                                                            │   │  │
│  │  │  def cvmm_kernel(a_ptr, b_ptr, c_ptr, indices, ...):                   │   │  │
│  │  │      for expert_id in selected_experts:                                 │   │  │
│  │  │          # Only load selected expert's weights                          │   │  │
│  │  │          w = load(b_ptr[expert_id])                                     │   │  │
│  │  │          # Compute matrix multiplication                                │   │  │
│  │  │          result += matmul(input, w) * weight[expert_id]                 │   │  │
│  │  │                                                                          │   │  │
│  │  │  Key: Skip 112 experts entirely!                                        │   │  │
│  │  │                                                                          │   │  │
│  │  └─────────────────────────────────────────────────────────────────────────┘   │  │
│  │                                                                                  │  │
│  └─────────────────────────────────────────────────────────────────────────────────┘  │
│                                                                                         │
│  Output: upd = [2, 1024, 1024]                                                         │
│                                                                                         │
└─────────────────────────────────────────────────────────────────────────────────────────┘
                                    │
                                    ▼
┌─────────────────────────────────────────────────────────────────────────────────────────┐
│  RESIDUAL CONNECTION + DROPOUT                                       ← L324             │
│  ═══════════════════════════════════════════════════════════════════════════════════    │
│                                                                                         │
│  x = x + strength * self.drop(upd)                                                     │
│  [2, 1024, 1024]                                                                       │
│                                                                                         │
│  return x, cache                                                                       │
│                                                                                         │
└─────────────────────────────────────────────────────────────────────────────────────────┘
```

---

## 训练时的熵正则化流程

```
┌─────────────────────────────────────────────────────────────────────────────────────────┐
│  ENTROPY REGULARIZATION (Preventing Expert Collapse)                ← L330-344          │
│  ═══════════════════════════════════════════════════════════════════════════════════    │
│                                                                                         │
│  Called during training by: model.collect_losses()                                     │
│                                                                                         │
│  ┌─────────────────────────────────────────────────────────────────────────────────┐  │
│  │ Step 1: Collect Selection Logits                                ← L331-344       │  │
│  │ ═══════════════════════════════════════════════════════════════════════════════ │  │
│  │                                                                                  │  │
│  │  During forward pass, each MoE layer stores:                                    │  │
│  │  • SigmaMoE:      sel_hist = [sel_raw_1, sel_raw_2, ...]                       │  │
│  │  • SwitchHead:    sel_hist = [sel_raw_v, sel_raw_o]                            │  │
│  │                                                                                  │  │
│  │  sel_raw shape: [batch, seq, n_experts]                                         │  │
│  │                                                                                  │  │
│  └─────────────────────────────────────────────────────────────────────────────────┘  │
│                                                                                         │
│  ┌─────────────────────────────────────────────────────────────────────────────────┐  │
│  │ Step 2: Compute Entropy Regularization                          ← L35-39        │  │
│  │ ═══════════════════════════════════════════════════════════════════════════════ │  │
│  │                                                                                  │  │
│  │  def entropy_reg(sel, dim, mask):                                               │  │
│  │      """                                                                         │  │
│  │      sel: [batch, seq, n_layers, n_experts]                                     │  │
│  │      """                                                                         │  │
│  │      # 1. Normalize across experts dimension                                    │  │
│  │      sel = F.log_softmax(sel, dim=-1)                           ← L36          │  │
│  │                                                                                  │  │
│  │      # 2. Average across layers/timesteps (in log domain)                       │  │
│  │      sel = log_mean(sel, dim, mask)                             ← L37          │  │
│  │      # Result: [batch, n_experts] or [n_experts]                               │  │
│  │                                                                                  │  │
│  │      # 3. Compute entropy: H = -Σ p*log(p)                                      │  │
│  │      entropy = -(sel * sel.exp()).sum(-1)                       ← L38          │  │
│  │                                                                                  │  │
│  │      # 4. Return negative entropy (minimize = maximize entropy)                 │  │
│  │      return -entropy.mean()                                     ← L39          │  │
│  │                                                                                  │  │
│  └─────────────────────────────────────────────────────────────────────────────────┘  │
│                                                                                         │
│  ┌─────────────────────────────────────────────────────────────────────────────────┐  │
│  │ Step 3: Aggregate Losses                                         ← L333-343      │  │
│  │ ═══════════════════════════════════════════════════════════════════════════════ │  │
│  │                                                                                  │  │
│  │  reg_loss = 0                                                                   │  │
│  │                                                                                  │  │
│  │  for layer in model.modules():                                                  │  │
│  │      if isinstance(layer, SigmaMoE):                                            │  │
│  │          # FFN entropy regularization (weight: 0.01)                            │  │
│  │          sel = stack(layer.sel_hist)  # [n_layers, B, L, E]                    │  │
│  │          reg_loss += 0.01 * entropy_reg(sel, dim=0)             ← L339         │  │
│  │                                                                                  │  │
│  │      elif isinstance(layer, SwitchHeadCore):                                    │  │
│  │          # Attention entropy regularization (weight: 0.001)                     │  │
│  │          reg_loss += 0.001 * layer.get_reg_loss()               ← L342         │  │
│  │                                                                                  │  │
│  │  return reg_loss                                                                │  │
│  │                                                                                  │  │
│  └─────────────────────────────────────────────────────────────────────────────────┘  │
│                                                                                         │
│  ┌─────────────────────────────────────────────────────────────────────────────────┐  │
│  │ Total Loss Computation                                                           │  │
│  │ ═══════════════════════════════════════════════════════════════════════════════ │  │
│  │                                                                                  │  │
│  │  total_loss = cross_entropy_loss + entropy_regularization                       │  │
│  │             = CE(logits, targets) + (0.01×FFN_ent + 0.001×Att_ent)             │  │
│  │                                                                                  │  │
│  │  Purpose:                                                                        │  │
│  │  • Prevent expert collapse (all tokens using same few experts)                  │  │
│  │  • Encourage diversity across layers and timesteps                              │  │
│  │  • Allow iterative expert reuse (with Sigmoid routing)                          │  │
│  │                                                                                  │  │
│  └─────────────────────────────────────────────────────────────────────────────────┘  │
│                                                                                         │
└─────────────────────────────────────────────────────────────────────────────────────────┘
```

---

## 专家选择可视化

```
┌─────────────────────────────────────────────────────────────────────────────────────────┐
│  SIGMOID vs SOFTMAX ROUTING COMPARISON                                                 │
│  ═══════════════════════════════════════════════════════════════════════════════════    │
│                                                                                         │
│  ┌─────────────────────────────────────────────────────────────────────────────────┐  │
│  │ Traditional MoE (Softmax Routing)                                                │  │
│  │ ───────────────────────────────────                                             │  │
│  │                                                                                  │  │
│  │  logits = [e1:2.0, e2:1.5, e3:1.8, e4:0.5, ..., e128:0.3]                      │  │
│  │    ↓ softmax (zero-sum game!)                                                   │  │
│  │  probs = [e1:0.35, e2:0.21, e3:0.28, e4:0.08, ..., e128:0.06]  sum=1.0        │  │
│  │    ↓ topk(k=16)                                                                 │  │
│  │  selected = [e1:0.35, e3:0.28, e2:0.21, ...]                                   │  │
│  │                                                                                  │  │
│  │  Problem: If e1 score increases → all others decrease!                          │  │
│  │  → Hard to reuse same expert in multiple layers                                 │  │
│  │                                                                                  │  │
│  └─────────────────────────────────────────────────────────────────────────────────┘  │
│                                                                                         │
│  ┌─────────────────────────────────────────────────────────────────────────────────┐  │
│  │ MoEUT (Sigmoid Routing)                                                          │  │
│  │ ─────────────────────────                                                       │  │
│  │                                                                                  │  │
│  │  logits = [e1:2.0, e2:1.5, e3:1.8, e4:0.5, ..., e128:0.3]                      │  │
│  │    ↓ sigmoid (independent scoring!)                                             │  │
│  │  probs = [e1:0.88, e2:0.82, e3:0.86, e4:0.62, ..., e128:0.57]                 │  │
│  │    ↓ topk(k=16)                                                                 │  │
│  │  selected = [e1:0.88, e3:0.86, e2:0.82, ...]                                   │  │
│  │                                                                                  │  │
│  │  Advantage: Each expert independently decides "Can I handle this?"              │  │
│  │  → Same expert can score high in multiple layers!                               │  │
│  │  → Enables iterative reasoning (e.g., "division expert" used 3 times)          │  │
│  │                                                                                  │  │
│  └─────────────────────────────────────────────────────────────────────────────────┘  │
│                                                                                         │
└─────────────────────────────────────────────────────────────────────────────────────────┘

┌─────────────────────────────────────────────────────────────────────────────────────────┐
│  EXPERT ACTIVATION PATTERN (Example: Solving Math Problem)                             │
│  ═══════════════════════════════════════════════════════════════════════════════════    │
│                                                                                         │
│  Problem: "What is ((14)/(-6))/(1162/(-4980))?"                                        │
│                                                                                         │
│  ┌─────────────────────────────────────────────────────────────────────────────────┐  │
│  │ Layer 0-1 (Understanding)                                                        │  │
│  │ ────────────────────────                                                        │  │
│  │ Token "What"    → Expert: [Language#12, Syntax#45, Question#78]                 │  │
│  │ Token "14"      → Expert: [Number#3, Digit#67, Math#89]                         │  │
│  │ Token "/"       → Expert: [Operator#23, Division#89, Math#89]                   │  │
│  │                                                                                  │  │
│  └─────────────────────────────────────────────────────────────────────────────────┘  │
│                                                                                         │
│  ┌─────────────────────────────────────────────────────────────────────────────────┐  │
│  │ Layer 2-3 (First Division: 14/-6)                                               │  │
│  │ ──────────────────────────────────                                              │  │
│  │ Token "14/-6"   → Expert: [Division#89, Negative#34, Fraction#56]  ⭐          │  │
│  │                   Division#89 is activated                                       │  │
│  │                                                                                  │  │
│  └─────────────────────────────────────────────────────────────────────────────────┘  │
│                                                                                         │
│  ┌─────────────────────────────────────────────────────────────────────────────────┐  │
│  │ Layer 4-5 (Second Division: 1162/-4980)                                         │  │
│  │ ───────────────────────────────────────                                         │  │
│  │ Token "1162"    → Expert: [Division#89, Negative#34, Fraction#56]  ⭐          │  │
│  │                   Division#89 is activated AGAIN! (iterative reuse)             │  │
│  │                                                                                  │  │
│  └─────────────────────────────────────────────────────────────────────────────────┘  │
│                                                                                         │
│  ┌─────────────────────────────────────────────────────────────────────────────────┐  │
│  │ Layer 6-8 (Combine Results)                                                     │  │
│  │ ───────────────────────────                                                     │  │
│  │ Combined result → Expert: [Division#89, Combine#12, Result#99]  ⭐             │  │
│  │                   Division#89 is activated THIRD TIME!                          │  │
│  │                                                                                  │  │
│  └─────────────────────────────────────────────────────────────────────────────────┘  │
│                                                                                         │
│  ┌─────────────────────────────────────────────────────────────────────────────────┐  │
│  │ Layer 9-17 (Verification & Output)                                              │  │
│  │ ──────────────────────────────────                                              │  │
│  │ Final result   → Expert: [Verify#45, Output#101, Format#23]                    │  │
│  │                                                                                  │  │
│  └─────────────────────────────────────────────────────────────────────────────────┘  │
│                                                                                         │
│  Key Insight:                                                                           │
│  • Division#89 expert is reused 3 times (layers 2-3, 4-5, 6-8)                        │
│  • This is LATENT ITERATIVE REASONING in vector space                                  │
│  • Standard Transformer cannot do this (no parameter sharing)                          │
│  • Similar to "mental arithmetic" - reusing same skill multiple times                  │
│                                                                                         │
└─────────────────────────────────────────────────────────────────────────────────────────┘
```

---

## 维度变化流程表

| 阶段 | 操作 | 输入维度 | 输出维度 | 说明 |
|------|------|----------|----------|------|
| **输入** | - | - | [2,1024,1024] | hidden states |
| **Pre-LN** | LayerNorm | [2,1024,1024] | [2,1024,1024] | |
| **注意力** | SwitchHeadRope | [2,1024,1024] | [2,1024,1024] | MoE attention |
| **残差1** | x + att | - | [2,1024,1024] | |
| **Pre-LN** | LayerNorm | [2,1024,1024] | [2,1024,1024] | |
| **FFN路由** | Sigmoid+TopK | [2,1024,1024] | weights:[2,1024,16] | Expert selection |
| **FFN Up** | cvmm(keys) | [2,1024,1024] | [2,1024,16,128] | Sparse computation |
| **激活** | ReLU/GELU | [2,1024,16,128] | [2,1024,16,128] | |
| **FFN Down** | cvmm(values) | [2,1024,16,128] | [2,1024,1024] | Weighted aggregation |
| **残差2** | x + ffn | - | [2,1024,1024] | |
| **输出** | - | - | [2,1024,1024] | |

---

## 参数量详细分解

```
┌────────────────────────────────────────────────────────────────────────────────┐
│                              Parameter Count (per MoEUTLayer)                   │
├────────────────────────────────────────────────────────────────────────────────┤
│                                                                                │
│  ┌─────────────────────────────────────────────────────────────────────────┐  │
│  │ MoE Attention (SwitchHeadRope)                                           │  │
│  │ ──────────────────────────────────                                      │  │
│  │                                                                          │  │
│  │ Standard Projections:                                                   │  │
│  │   q_proj:  [1024, 1024] = 1,048,576                                     │  │
│  │   k_proj:  [1024, 1024] = 1,048,576                                     │  │
│  │                                                                          │  │
│  │ V Projection (per head, per expert):                                    │  │
│  │   v_proj:  [n_heads × n_experts, state_size, proj_size]                │  │
│  │          = [8 × 10, 1024, 128]                                          │  │
│  │          = 10,485,760                                                   │  │
│  │                                                                          │  │
│  │ O Projection (per head, per expert):                                    │  │
│  │   o_proj:  [8 × 10, proj_size, state_size]                             │  │
│  │          = [80, 128, 1024]                                              │  │
│  │          = 10,485,760                                                   │  │
│  │                                                                          │  │
│  │ Expert Selection (per head):                                            │  │
│  │   sel_v:   [8 × 10, 1024] = 81,920                                     │  │
│  │   sel_o:   [8 × 10, 1024] = 81,920                                     │  │
│  │                                                                          │  │
│  │                        ───────────                                       │  │
│  │ Subtotal:              23,232,512 (23.23M)                              │  │
│  └─────────────────────────────────────────────────────────────────────────┘  │
│                                                                                │
│  ┌─────────────────────────────────────────────────────────────────────────┐  │
│  │ MoE FFN (SigmaMoE)                                                       │  │
│  │ ──────────────────────                                                  │  │
│  │                                                                          │  │
│  │ Expert Up Projections:                                                  │  │
│  │   keys:    [n_experts, dmodel, expert_size]                             │  │
│  │          = [128, 1024, 128]                                             │  │
│  │          = 16,777,216                                                   │  │
│  │                                                                          │  │
│  │ Expert Down Projections:                                                │  │
│  │   values:  [128, 128, 1024]                                             │  │
│  │          = 16,777,216                                                   │  │
│  │                                                                          │  │
│  │ Expert Selection:                                                        │  │
│  │   expert_sel: [128, 1024] = 131,072                                     │  │
│  │                                                                          │  │
│  │                        ───────────                                       │  │
│  │ Subtotal:              33,685,504 (33.69M)                              │  │
│  └─────────────────────────────────────────────────────────────────────────┘  │
│                                                                                │
│  ┌─────────────────────────────────────────────────────────────────────────┐  │
│  │ Layer Normalization                                                      │  │
│  │ ───────────────────                                                     │  │
│  │ ln1: RMSNorm [1024] ≈ 1,024                                             │  │
│  │ ln2: RMSNorm [1024] ≈ 1,024                                             │  │
│  │                        ──────                                            │  │
│  │ Subtotal:              2,048 (0.002M)                                    │  │
│  └─────────────────────────────────────────────────────────────────────────┘  │
│                                                                                │
│  ═══════════════════════════════════════════════════════════════════════════  │
│  TOTAL PARAMETERS PER LAYER: ~56.92M                                          │
│  ═══════════════════════════════════════════════════════════════════════════  │
│                                                                                │
│  For 18-layer model with group_size=2:                                        │
│  • Physical layers: 18 / 2 = 9                                                │
│  • Parameters: 56.92M × 9 = 512.3M                                            │
│  • Plus embeddings: ~200M                                                     │
│  • Total: ~712M parameters                                                    │
│                                                                                │
│  Comparison with standard 18-layer Transformer:                               │
│  • Standard Transformer: ~800M parameters                                     │
│  • MoEUT: ~712M parameters (11% fewer)                                        │
│  • But MoEUT uses parameter sharing → effective params even lower!            │
│                                                                                │
└────────────────────────────────────────────────────────────────────────────────┘
```

---

## 激活参数对比

```
┌─────────────────────────────────────────────────────────────────────────────────────────┐
│  ACTIVATION PARAMETERS COMPARISON                                                      │
│  ═══════════════════════════════════════════════════════════════════════════════════    │
│                                                                                         │
│  Configuration: state_size=1024, n_experts=128, k=16, batch=2, seq=1024                │
│                                                                                         │
│  ┌─────────────────────────────────────────────────────────────────────────────────┐  │
│  │ Standard Transformer FFN (Dense)                                                 │  │
│  │ ───────────────────────────────────                                             │  │
│  │                                                                                  │  │
│  │  All parameters activated:                                                       │  │
│  │  • Up projection:   [1024, 4096] = 4.19M                                        │  │
│  │  • Down projection: [4096, 1024] = 4.19M                                        │  │
│  │  • Total:           8.39M parameters                                            │  │
│  │  • Activation ratio: 100%                                                       │  │
│  │                                                                                  │  │
│  └─────────────────────────────────────────────────────────────────────────────────┘  │
│                                                                                         │
│  ┌─────────────────────────────────────────────────────────────────────────────────┐  │
│  │ MoEUT SigmaMoE (Sparse)                                                          │  │
│  │ ─────────────────────────                                                       │  │
│  │                                                                                  │  │
│  │  Total parameters:                                                               │  │
│  │  • Up projection:   [128, 1024, 128] = 16.78M                                   │  │
│  │  • Down projection: [128, 128, 1024] = 16.78M                                   │  │
│  │  • Total:           33.56M parameters                                           │  │
│  │                                                                                  │  │
│  │  Activated per forward pass:                                                     │  │
│  │  • Selected experts: 16 out of 128                                              │  │
│  │  • Up projection:    [16, 1024, 128] = 2.10M                                    │  │
│  │  • Down projection:  [16, 128, 1024] = 2.10M                                    │  │
│  │  • Total activated:  4.20M parameters                                           │  │
│  │  • Activation ratio: 12.5% (16/128)                                             │  │
│  │                                                                                  │  │
│  │  ┌─────────────────────────────────────────────────────────────────────────┐   │  │
│  │  │ Comparison:                                                              │   │  │
│  │  │ ────────────                                                            │   │  │
│  │  │ Standard Transformer:  8.39M activated (100%)                           │   │  │
│  │  │ MoEUT:                 4.20M activated (50% of standard)                │   │  │
│  │  │                                                                          │   │  │
│  │  │ • Similar activated parameters                                          │   │  │
│  │  │ • But MoEUT has 4× more total capacity!                                 │   │  │
│  │  │ • Different tokens can use different experts                            │   │  │
│  │  │ • Enables specialization and iterative reasoning                        │   │  │
│  │  └─────────────────────────────────────────────────────────────────────────┘   │  │
│  │                                                                                  │  │
│  └─────────────────────────────────────────────────────────────────────────────────┘  │
│                                                                                         │
└─────────────────────────────────────────────────────────────────────────────────────────┘
```

---

## 与标准Transformer对比

```
┌─────────────────────────────────────────────────────────────────────────────────────────┐
│                      MoEUT vs Standard Transformer Comparison                           │
├─────────────────────────────────────────────────────────────────────────────────────────┤
│                                                                                         │
│  ┌─────────────────────────────────┐    ┌─────────────────────────────────┐           │
│  │   Standard Transformer          │    │          MoEUT                  │           │
│  │  ┌─────────────────────────┐   │    │  ┌─────────────────────────┐   │           │
│  │  │ Layer Structure         │   │    │  │ Layer Structure         │   │           │
│  │  │                         │   │    │  │                         │   │           │
│  │  │ Layer 0: Unique params │   │    │  │ Layer 0: Shared group 0 │   │           │
│  │  │ Layer 1: Unique params │   │    │  │ Layer 1: Shared group 1 │   │           │
│  │  │ Layer 2: Unique params │   │    │  │ Layer 2: Shared group 0 │◄──┼─ Reuse!  │
│  │  │ ...                    │   │    │  │ Layer 3: Shared group 1 │◄──┼─ Reuse!  │
│  │  │ Layer 17: Unique params│   │    │  │ ...                     │   │           │
│  │  │                         │   │    │  │ Layer 17: Shared group 1│   │           │
│  │  │ Total: 18 unique layers│   │    │  │ Total: 9 unique layers  │   │           │
│  │  └─────────────────────────┘   │    │  └─────────────────────────┘   │           │
│  │                                 │    │                                 │           │
│  │  Parameters: ~800M              │    │  Parameters: ~712M              │           │
│  │  Effective params: ~800M        │    │  Effective params: ~356M!       │           │
│  └─────────────────────────────────┘    └─────────────────────────────────┘           │
│                                                                                         │
│  ┌─────────────────────────────────┐    ┌─────────────────────────────────┐           │
│  │   Computation Per Layer         │    │   Computation Per Layer         │           │
│  │  ┌─────────────────────────┐   │    │  ┌─────────────────────────┐   │           │
│  │  │ FFN: All params used    │   │    │  │ FFN: Sparse activation  │   │           │
│  │  │ Up: [1024→4096]         │   │    │  │ Select 16/128 experts   │   │           │
│  │  │ Down: [4096→1024]       │   │    │  │ Compute only selected   │   │           │
│  │  │                         │   │    │  │                         │   │           │
│  │  │ FLOPs: ~17M per token   │   │    │  │ FLOPs: ~8.4M per token  │   │           │
│  │  └─────────────────────────┘   │    │  └─────────────────────────┘   │           │
│  │                                 │    │                                 │           │
│  │  Speedup: 1.0×                  │    │  Speedup: 2.0×                  │           │
│  └─────────────────────────────────┘    └─────────────────────────────────┘           │
│                                                                                         │
│  ┌─────────────────────────────────┐    ┌─────────────────────────────────┐           │
│  │   Depth Utilization             │    │   Depth Utilization             │           │
│  │  ┌─────────────────────────┐   │    │  ┌─────────────────────────┐   │           │
│  │  │ Layers 0-8:  Active     │   │    │  │ All layers can be active│   │           │
│  │  │ Layers 9-17: Idle       │   │    │  │ through parameter reuse │   │           │
│  │  │              (refining) │   │    │  │ and expert selection    │   │           │
│  │  │                         │   │    │  │                         │   │           │
│  │  │ Effective depth: ~50%   │   │    │  │ Effective depth: ~90%   │   │           │
│  │  └─────────────────────────┘   │    │  └─────────────────────────┘   │           │
│  └─────────────────────────────────┘    └─────────────────────────────────┘           │
│                                                                                         │
│  ═══════════════════════════════════════════════════════════════════════════════════   │
│                                                                                         │
│  Performance on Math Reasoning (DeepMind Math, Answer-only mode):                     │
│  ┌─────────────────────────────────────────────────────────────────────────────────┐  │
│  │                                                                                  │  │
│  │  Standard Transformer:  ██████████████████████████████                48%       │  │
│  │                                                                                  │  │
│  │  MoEUT:                 ████████████████████████████████████████████  63%       │  │
│  │                                                                                  │  │
│  │                                                    Improvement: +15% 🔥         │  │
│  │                                                                                  │  │
│  └─────────────────────────────────────────────────────────────────────────────────┘  │
│                                                                                         │
│  Key Advantages:                                                                       │
│  • Parameter sharing → Iterative computation possible                                  │
│  • Sparse activation → Efficient inference                                             │
│  • Sigmoid routing → Same expert can be reused across layers                           │
│  • Entropy regularization → All experts get trained                                    │
│  • Better depth utilization → Superior reasoning on complex problems                   │
│                                                                                         │
└─────────────────────────────────────────────────────────────────────────────────────────┘
```

---

## 训练配置详细对比

```
┌─────────────────────────────────────────────────────────────────────────────────────────┐
│                      Training Configuration Comparison                                  │
├─────────────────────────────────────────────────────────────────────────────────────────┤
│                                                                                         │
│  Hyperparameter                   Standard Transformer    MoEUT           Notes        │
│  ────────────────────────────────────────────────────────────────────────────────────  │
│                                                                                         │
│  MODEL ARCHITECTURE                                                                    │
│  ───────────────────                                                                   │
│  Hidden dimension                 1024                   1024                          │
│  Number of layers                 18                     18             (9 physical)   │
│  Attention heads                  16                     4              MoEUT fewer    │
│  Head projection size             64 (1024/16)           128            MoEUT larger   │
│  FFN multiplier                   4.014                  N/A            Standard only  │
│  FFN experts                      N/A                    387            MoEUT only     │
│  FFN expert size                  N/A                    128            MoEUT only     │
│  FFN Top-K                        N/A                    16             MoEUT only     │
│  Attention experts                N/A                    10             MoEUT only     │
│  Attention Top-K                  N/A                    2              MoEUT only     │
│  Parameter sharing (group_size)   N/A                    2              MoEUT only     │
│                                                                                         │
│  TRAINING HYPERPARAMETERS                                                              │
│  ─────────────────────────                                                             │
│  Learning rate                    0.00025                0.00025        Same           │
│  Weight decay                     0.01                   0.01           Same           │
│  Batch size                       64                     64             Same           │
│  Gradient clipping                0.25                   0.25           Same           │
│  LR scheduler                     Cosine                 Cosine         Same           │
│  LR warmup steps                  4000                   4000           Same           │
│  Total training steps             100000                 100000         Same           │
│  Min LR multiplier                0.1                    0.1            Same           │
│  Sequence length                  1024                   1024           Same           │
│                                                                                         │
│  SPECIAL CONFIGURATIONS                                                                │
│  ───────────────────────                                                               │
│  Microbatches                     1                      2              MoEUT needs    │
│  Mixed precision                  FP16                   BFloat16       MoEUT stable   │
│  Torch compile                    ✅                     ❌              Triton conflict│
│  Entropy regularization           ❌                     ✅ (0.01/0.001) MoEUT only     │
│  Expert dropout                   ❌                     ✅ (varies)     MoEUT only     │
│                                                                                         │
│  LOSS FUNCTION                                                                         │
│  ──────────────                                                                        │
│  Base loss                        Cross-entropy          Cross-entropy  Same           │
│  Regularization                   None                   Entropy reg    MoEUT only     │
│                                                                                         │
│  TRAINING MODES                                                                        │
│  ───────────────                                                                       │
│  loss_on_target_only=False (Q+A)  41% accuracy          36% accuracy   Both trained   │
│  loss_on_target_only=True (A-only) 48% accuracy         63% accuracy   +15% 🔥        │
│                                                                                         │
│  MEMORY & SPEED                                                                        │
│  ───────────────────                                                                   │
│  Training speed                   1.0× (baseline)        0.8× (slower)  Sparse compute │
│  Memory usage                     12GB                   18GB (w/ μbatch) More experts │
│  GPU utilization                  95%                    85%            Sparse ops     │
│                                                                                         │
│  EFFECTIVE PARAMETERS                                                                  │
│  ─────────────────────                                                                 │
│  Total parameters                 800M                   712M           MoEUT 11% less │
│  Effective (unique) params        800M                   ~356M          50% reduction! │
│  Activated params per token       800M                   ~90M           Sparse         │
│                                                                                         │
└─────────────────────────────────────────────────────────────────────────────────────────┘
```

---

## 代码结构与文件对应

```
┌─────────────────────────────────────────────────────────────────────────────────────────┐
│                              Code Structure Mapping                                     │
├─────────────────────────────────────────────────────────────────────────────────────────┤
│                                                                                         │
│  llm_effective_depth-master/training/                                                  │
│  │                                                                                      │
│  ├── layers/                                  ◄─── Core Layer Implementations          │
│  │   ├── moeut.py                             ◄─── MoEUT Main Layer                   │
│  │   │   ├── SigmaMoE               [L41-126]     MoE FFN with Sigmoid routing        │
│  │   │   │   ├── __init__()          [L43-77]      Initialize experts                 │
│  │   │   │   ├── init_sel()          [L167-169]    Initialize selection weights       │
│  │   │   │   ├── forward()           [L79-107]     Sparse expert computation          │
│  │   │   │   └── get_reg_loss()      [L35-39]      Entropy regularization             │
│  │   │   ├── SwitchHeadCore          [L128-239]    MoE Attention base                 │
│  │   │   │   ├── get_sel()           [L196-210]    Expert selection (Sigmoid+TopK)    │
│  │   │   │   └── forward()           [L212-239]    Attention with expert routing      │
│  │   │   ├── SwitchHeadRope          [L286-284]    MoE Attention with RoPE            │
│  │   │   └── MoEUTLayer              [L297-319]    Complete layer (Att+FFN)           │
│  │   │       ├── __init__()          [L299-316]    Setup attention + FFN              │
│  │   │       └── forward()           [L317-324]    Layer forward pass                 │
│  │   ├── universal_transformer.py    ◄─── Parameter Sharing Framework                 │
│  │   │   └── UniversalTransformer    [L16-51]      │
│  │   │       ├── __init__()          [L18-30]      Create shared layers               │
│  │   │       └── forward()           [L32-51]      Iterative application              │
│  │   └── cvmm.py                     ◄─── Sparse Expert Computation                   │
│  │       ├── cvmm_prepare_sel2()     [L74-137]     Prepare selection indices          │
│  │       ├── cvmm_triton()           [L158-290]    Triton kernel (forward)            │
│  │       └── cvmm_triton_backward()  [L434-470]    Triton kernel (backward)           │
│  │                                                                                      │
│  ├── tasks/                                   ◄─── Task Definitions                    │
│  │   ├── dm_math.py                           DeepMind Math dataset task              │
│  │   │   ├── DMMathMixin             [L13-45]      Dataset loading mixin              │
│  │   │   ├── DMMathTransformer       [L47-49]      Standard transformer task          │
│  │   │   └── DMMathMoeut             [L52-54]      MoEUT task                         │
│  │   └── helpers/                                                                      │
│  │       ├── lm_mixin.py              [L1-99]       Language model utilities           │
│  │       │   └── loss()              [L21-28]      Loss computation (with mask)       │
│  │       └── transformer_templates.py [L1-170]     Model templates                    │
│  │           ├── TransformerTask      [L68-95]      Standard transformer              │
│  │           └── MoEUTTask            [L98-126]     MoEUT template                    │
│  │                                                                                      │
│  ├── framework/                               ◄─── Training Framework                  │
│  │   ├── task/                                                                         │
│  │   │   ├── task.py                 [L1-408]      Base task class                    │
│  │   │   │   ├── create_lr_scheduler()[L65-78]     LR scheduling setup                │
│  │   │   │   ├── set_lr()            [L169-186]    LR warmup + schedule               │
│  │   │   │   └── validate()          [L332-333]    Validation loop                    │
│  │   │   └── simple_task.py          [L1-580]      Training loop                      │
│  │   │       ├── train_step()        [L402-511]    Single training step               │
│  │   │       ├── run_ubatch()        [L435-454]    Microbatch processing              │
│  │   │       └── get_regularizers()  [L354-356]    Collect entropy losses             │
│  │   └── helpers/                                                                      │
│  │       └── training_helper.py      [L1-466]      Training utilities                 │
│  │                                                                                      │
│  └── sweeps/                                  ◄─── Training Configurations             │
│      ├── dm_math_moeut_big_lossonall_vs_noloss.yaml                                   │
│      │                                        MoEUT training config                    │
│      └── dm_math_transformer_lossonall_vs_noloss.yaml                                 │
│                                               Standard transformer config              │
│                                                                                         │
│  Key Dependencies:                                                                      │
│  ├── torch                             PyTorch framework                               │
│  ├── torch.distributed.optim           ZeroRedundancyOptimizer                         │
│  ├── triton                            JIT compiler for cvmm kernels                   │
│  └── einops                            Tensor manipulation (rearrange, repeat)         │
│                                                                                         │
└─────────────────────────────────────────────────────────────────────────────────────────┘
```

---

## 关键创新点总结

```
┌─────────────────────────────────────────────────────────────────────────────────────────┐
│                              MoEUT Key Innovations                                      │
├─────────────────────────────────────────────────────────────────────────────────────────┤
│                                                                                         │
│  1. UNIVERSAL TRANSFORMER (Parameter Sharing)                           ⭐⭐⭐⭐⭐      │
│     ─────────────────────────────────────────────                                      │
│     • 18 logical layers using only 9 physical layers                                   │
│     • Same parameters applied iteratively                                              │
│     • Enables "latent space Chain-of-Thought"                                          │
│     • Similar to brain reusing same neural circuits                                    │
│                                                                                         │
│  2. SIGMOID ROUTING (Non-competitive Expert Selection)                 ⭐⭐⭐⭐⭐      │
│     ───────────────────────────────────────────────                                    │
│     • Independent expert scoring (not zero-sum like Softmax)                           │
│     • Allows same expert to be selected in multiple layers                             │
│     • Critical for iterative reasoning (e.g., "division expert" reused 3 times)        │
│     • Works with entropy regularization to prevent collapse                            │
│                                                                                         │
│  3. CVMM SPARSE COMPUTATION (Triton-optimized)                         ⭐⭐⭐⭐⭐      │
│     ───────────────────────────────────────────                                        │
│     • Only computes selected experts (16 out of 128)                                   │
│     • 8× speedup compared to dense computation                                         │
│     • Custom Triton kernels for forward and backward                                   │
│     • Sparse gradients → only selected experts updated                                 │
│                                                                                         │
│  4. ENTROPY REGULARIZATION (Preventing Expert Collapse)                ⭐⭐⭐⭐        │
│     ────────────────────────────────────────────────                                   │
│     • Maximizes entropy of expert selection distribution                               │
│     • Encourages diversity across layers and timesteps                                 │
│     • FFN: weight 0.01, Attention: weight 0.001                                        │
│     • Soft constraint (not hard like load balancing)                                   │
│                                                                                         │
│  5. DUAL MOE (Attention + FFN)                                         ⭐⭐⭐⭐        │
│     ──────────────────────────                                                         │
│     • Traditional MoE: only FFN uses experts                                           │
│     • MoEUT: Both attention and FFN use experts                                        │
│     • Finer-grained specialization                                                     │
│     • V and O projections both have expert routing                                     │
│                                                                                         │
│  6. BFLOAT16 MIXED PRECISION                                           ⭐⭐⭐          │
│     ─────────────────────────                                                          │
│     • More stable than FP16 (same exponent range as FP32)                              │
│     • No gradient scaler needed                                                        │
│     • Prevents gradient underflow/overflow                                             │
│                                                                                         │
│  7. MICROBATCH GRADIENT ACCUMULATION                                   ⭐⭐⭐          │
│     ────────────────────────────────────                                               │
│     • n_microbatch=2 to handle large expert parameter count                            │
│     • Reduces peak memory by ~40%                                                      │
│     • Enables training on consumer GPUs                                                │
│                                                                                         │
│  ═══════════════════════════════════════════════════════════════════════════════════   │
│                                                                                         │
│  Result: "Latent Iterative Reasoning"                                                  │
│  • Answer-only mode: 63% vs 48% (+15% over standard Transformer) 🔥                   │
│  • Proof of genuine iterative computation in latent space                              │
│  • Not dependent on externalizing reasoning steps (like CoT)                           │
│  • Uses fewer effective parameters (356M vs 800M)                                      │
│                                                                                         │
└─────────────────────────────────────────────────────────────────────────────────────────┘
```

---

*文档创建时间: 2025-12-15*
*基于论文: "Do Language Models Use Their Depth Efficiently?" (NeurIPS 2025)*
*代码仓库: https://github.com/robertcsordas/llm_effective_depth*
